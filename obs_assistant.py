import sys
import cv2
import numpy as np
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, QPushButton, 
                           QLabel, QHBoxLayout, QTextEdit, QGroupBox, QLineEdit, 
                           QCheckBox, QSpinBox, QComboBox, QTabWidget, QListWidget,
                           QSplitter, QDialog, QDialogButtonBox, QFormLayout, QScrollArea,
                           QProgressBar, QMessageBox, QFileDialog, QMenuBar, QAction,
                           QSystemTrayIcon, QMenu, QShortcut, QToolTip, QDockWidget,
                           QDesktopWidget, QFrame)
from PyQt5.QtCore import Qt, QTimer, QRectF, QPointF, pyqtSignal, QThread, pyqtSlot, QSettings, QRect
from PyQt5.QtGui import QImage, QPixmap, QPainter, QPen, QColor, QFont, QKeySequence, QIcon
import pytesseract
import pyperclip
from PIL import Image
import os
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime
import json
import sounddevice as sd
import tempfile
import requests
import wave
import re
import logging
import traceback
from pathlib import Path


class FloatingResponseWindow(QMainWindow):
    """–ü–ª–∞–≤–∞—é—â–µ–µ –æ–∫–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("üí¨ Quick Responses")
        self.setWindowFlags(Qt.Window | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_DeleteOnClose, False)  # –ù–µ —É–¥–∞–ª—è—Ç—å –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏ –ø–æ–∑–∏—Ü–∏—é
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        self.setGeometry(screen_rect.width() - 500, 100, 480, 400)
        
        self.setup_ui()
        
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        central_widget.setLayout(layout)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_label = QLabel("üí¨ Quick Responses")
        title_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50; padding: 10px;")
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞
        question_layout = QHBoxLayout()
        self.question_input = QLineEdit()
        self.question_input.setPlaceholderText("Enter question to generate quick responses...")
        self.question_input.returnPressed.connect(self.generate_responses_signal)
        question_layout.addWidget(self.question_input)
        
        self.generate_btn = QPushButton("üöÄ Generate")
        self.generate_btn.clicked.connect(self.generate_responses_signal)
        question_layout.addWidget(self.generate_btn)
        
        layout.addLayout(question_layout)
        
        # –°—Ç–∞—Ç—É—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.status_label = QLabel("Ready to generate responses...")
        self.status_label.setStyleSheet("color: #7f8c8d; font-style: italic; padding: 5px;")
        layout.addWidget(self.status_label)
        
        # –†—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—Ç
        ru_group = QGroupBox("üá∑üá∫ Russian Response")
        ru_layout = QVBoxLayout()
        
        self.ru_response_area = QTextEdit()
        self.ru_response_area.setMaximumHeight(120)
        self.ru_response_area.setFont(QFont("Consolas", 10))
        self.ru_response_area.setPlaceholderText("–†—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å...")
        self.ru_response_area.setStyleSheet("QTextEdit { background-color: #f8f9fa; border: 1px solid #dee2e6; }")
        ru_layout.addWidget(self.ru_response_area)
        
        ru_buttons = QHBoxLayout()
        copy_ru_btn = QPushButton("üìã Copy RU")
        copy_ru_btn.clicked.connect(self.copy_ru_response)
        copy_ru_btn.setStyleSheet("QPushButton { background-color: #28a745; color: white; }")
        ru_buttons.addWidget(copy_ru_btn)
        ru_buttons.addStretch()
        ru_layout.addLayout(ru_buttons)
        
        ru_group.setLayout(ru_layout)
        layout.addWidget(ru_group)
        
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π –æ—Ç–≤–µ—Ç
        en_group = QGroupBox("üá∫üá∏ English Response")
        en_layout = QVBoxLayout()
        
        self.en_response_area = QTextEdit()
        self.en_response_area.setMaximumHeight(120)
        self.en_response_area.setFont(QFont("Consolas", 10))
        self.en_response_area.setPlaceholderText("English response will appear here...")
        self.en_response_area.setStyleSheet("QTextEdit { background-color: #f8f9fa; border: 1px solid #dee2e6; }")
        en_layout.addWidget(self.en_response_area)
        
        en_buttons = QHBoxLayout()
        copy_en_btn = QPushButton("üìã Copy EN")
        copy_en_btn.clicked.connect(self.copy_en_response)
        copy_en_btn.setStyleSheet("QPushButton { background-color: #007bff; color: white; }")
        en_buttons.addWidget(copy_en_btn)
        en_buttons.addStretch()
        en_layout.addLayout(en_buttons)
        
        en_group.setLayout(en_layout)
        layout.addWidget(en_group)
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–∫–Ω–æ–º
        control_layout = QHBoxLayout()
        
        self.pin_btn = QPushButton("üìå Pin")
        self.pin_btn.setCheckable(True)
        self.pin_btn.toggled.connect(self.toggle_pin)
        self.pin_btn.setToolTip("–ó–∞–∫—Ä–µ–ø–∏—Ç—å –æ–∫–Ω–æ –ø–æ–≤–µ—Ä—Ö –≤—Å–µ—Ö")
        control_layout.addWidget(self.pin_btn)
        
        self.minimize_btn = QPushButton("‚ûñ Minimize")
        self.minimize_btn.clicked.connect(self.showMinimized)
        control_layout.addWidget(self.minimize_btn)
        
        control_layout.addStretch()
        
        self.close_btn = QPushButton("‚ùå Close")
        self.close_btn.clicked.connect(self.hide)
        self.close_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; }")
        control_layout.addWidget(self.close_btn)
        
        layout.addLayout(control_layout)
        
    def generate_responses_signal(self):
        """–°–∏–≥–Ω–∞–ª –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤"""
        self.generate_responses_requested.emit(self.question_input.text())
        
    generate_responses_requested = pyqtSignal(str)
    
    def set_responses(self, ru_text, en_text):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"""
        self.ru_response_area.setText(ru_text)
        self.en_response_area.setText(en_text)
        self.status_label.setText("‚úÖ Responses generated successfully!")
        
    def set_status(self, status):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å"""
        self.status_label.setText(status)
        
    def set_question(self, question):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤–æ–ø—Ä–æ—Å"""
        self.question_input.setText(question)
        
    def copy_ru_response(self):
        """–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—Ç"""
        text = self.ru_response_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("üìã Russian response copied!")
            
    def copy_en_response(self):
        """–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∞–Ω–≥–ª–∏–π—Å–∫–∏–π –æ—Ç–≤–µ—Ç"""
        text = self.en_response_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("üìã English response copied!")
            
    def toggle_pin(self, checked):
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–∫–Ω–∞"""
        if checked:
            self.setWindowFlags(self.windowFlags() | Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("üìå Pinned")
            self.pin_btn.setStyleSheet("QPushButton { background-color: #ffc107; }")
        else:
            self.setWindowFlags(self.windowFlags() & ~Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("üìå Pin")
            self.pin_btn.setStyleSheet("")
        self.show()
        
    def closeEvent(self, event):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–∫—Ä—ã—Ç–∏–µ - –ø—Ä–æ—Å—Ç–æ —Å–∫—Ä—ã–≤–∞–µ–º"""
        event.ignore()
        self.hide()


class FloatingAudioWindow(QMainWindow):
    """–ü–ª–∞–≤–∞—é—â–µ–µ –æ–∫–Ω–æ –¥–ª—è –∞—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("üé§ Audio Transcription")
        self.setWindowFlags(Qt.Window | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_DeleteOnClose, False)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏ –ø–æ–∑–∏—Ü–∏—é
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        self.setGeometry(50, 100, 600, 500)
        
        self.setup_ui()
        
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        central_widget.setLayout(layout)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∫–æ–Ω—Ç—Ä–æ–ª–∞–º–∏ –∑–∞–ø–∏—Å–∏
        header_layout = QHBoxLayout()
        
        title_label = QLabel("üé§ Audio Transcription")
        title_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50;")
        header_layout.addWidget(title_label)
        
        header_layout.addStretch()
        
        self.record_btn = QPushButton("üé§ Start Recording")
        self.record_btn.setStyleSheet("QPushButton { font-size: 14px; padding: 8px; }")
        self.record_btn.clicked.connect(self.toggle_recording_signal)
        header_layout.addWidget(self.record_btn)
        
        layout.addLayout(header_layout)
        
        # –°—Ç–∞—Ç—É—Å –∑–∞–ø–∏—Å–∏
        self.status_label = QLabel("Ready to record")
        self.status_label.setStyleSheet("color: #7f8c8d; font-style: italic; padding: 5px;")
        layout.addWidget(self.status_label)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        transcription_group = QGroupBox("üì¢ Real-time Transcription")
        transcription_layout = QVBoxLayout()
        
        self.transcription_area = QTextEdit()
        self.transcription_area.setFont(QFont("Consolas", 11))
        self.transcription_area.setPlaceholderText("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å...")
        self.transcription_area.setStyleSheet("QTextEdit { background-color: #f0f0f0; border: 1px solid #ccc; }")
        transcription_layout.addWidget(self.transcription_area)
        
        transcription_group.setLayout(transcription_layout)
        layout.addWidget(transcription_group)
        
        # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        processed_group = QGroupBox("ü§ñ Processed Text")
        processed_layout = QVBoxLayout()
        
        self.processed_area = QTextEdit()
        self.processed_area.setFont(QFont("Consolas", 11))
        self.processed_area.setPlaceholderText("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å...")
        self.processed_area.setStyleSheet("QTextEdit { background-color: #e8f5e8; border: 1px solid #28a745; }")
        processed_layout.addWidget(self.processed_area)
        
        processed_buttons = QHBoxLayout()
        copy_audio_btn = QPushButton("üìã Copy Audio")
        copy_audio_btn.clicked.connect(self.copy_processed_text)
        copy_audio_btn.setStyleSheet("QPushButton { background-color: #28a745; color: white; }")
        processed_buttons.addWidget(copy_audio_btn)
        
        save_audio_btn = QPushButton("üíæ Save Audio")
        save_audio_btn.clicked.connect(self.save_audio_text_signal)
        processed_buttons.addWidget(save_audio_btn)
        
        processed_buttons.addStretch()
        processed_layout.addLayout(processed_buttons)
        
        processed_group.setLayout(processed_layout)
        layout.addWidget(processed_group)
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–∫–Ω–æ–º
        control_layout = QHBoxLayout()
        
        self.pin_btn = QPushButton("üìå Pin")
        self.pin_btn.setCheckable(True)
        self.pin_btn.toggled.connect(self.toggle_pin)
        control_layout.addWidget(self.pin_btn)
        
        self.clear_btn = QPushButton("üóëÔ∏è Clear")
        self.clear_btn.clicked.connect(self.clear_all_text)
        control_layout.addWidget(self.clear_btn)
        
        control_layout.addStretch()
        
        self.close_btn = QPushButton("‚ùå Close")
        self.close_btn.clicked.connect(self.hide)
        self.close_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; }")
        control_layout.addWidget(self.close_btn)
        
        layout.addLayout(control_layout)
        
    toggle_recording_requested = pyqtSignal()
    save_audio_text_requested = pyqtSignal()
    
    def toggle_recording_signal(self):
        """–°–∏–≥–Ω–∞–ª –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏"""
        self.toggle_recording_requested.emit()
        
    def save_audio_text_signal(self):
        """–°–∏–≥–Ω–∞–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ —Ç–µ–∫—Å—Ç–∞"""
        self.save_audio_text_requested.emit()
        
    def set_recording_state(self, is_recording):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∑–∞–ø–∏—Å–∏"""
        if is_recording:
            self.record_btn.setText("‚èπÔ∏è Stop Recording")
            self.record_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; font-size: 14px; padding: 8px; }")
            self.status_label.setText("üî¥ Recording...")
        else:
            self.record_btn.setText("üé§ Start Recording")
            self.record_btn.setStyleSheet("QPushButton { font-size: 14px; padding: 8px; }")
            self.status_label.setText("Ready to record")
            
    def add_transcription(self, text):
        """–î–æ–±–∞–≤–∏—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é"""
        self.transcription_area.append(text)
        
    def add_processed_text(self, text):
        """–î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        self.processed_area.append(text)
        
    def set_status(self, status):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å"""
        self.status_label.setText(status)
        
    def copy_processed_text(self):
        """–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        text = self.processed_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("üìã Processed text copied!")
            
    def clear_all_text(self):
        """–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç"""
        self.transcription_area.clear()
        self.processed_area.clear()
        self.status_label.setText("Text cleared")
        
    def toggle_pin(self, checked):
        """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–∫–Ω–∞"""
        if checked:
            self.setWindowFlags(self.windowFlags() | Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("üìå Pinned")
            self.pin_btn.setStyleSheet("QPushButton { background-color: #ffc107; }")
        else:
            self.setWindowFlags(self.windowFlags() & ~Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("üìå Pin")
            self.pin_btn.setStyleSheet("")
        self.show()
        
    def closeEvent(self, event):
        """–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–∫—Ä—ã—Ç–∏–µ - –ø—Ä–æ—Å—Ç–æ —Å–∫—Ä—ã–≤–∞–µ–º"""
        event.ignore()
        self.hide()


class StatusWidget(QWidget):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –≤–∏–¥–∂–µ—Ç —Å—Ç–∞—Ç—É—Å–∞ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º"""
    def __init__(self):
        super().__init__()
        layout = QHBoxLayout()
        
        self.status_label = QLabel("Ready")
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        self.progress_bar.setMaximumWidth(200)
        self.progress_bar.setStyleSheet("""
            QProgressBar {
                border: 1px solid #bdc3c7;
                border-radius: 5px;
                text-align: center;
            }
            QProgressBar::chunk {
                background-color: #3498db;
                border-radius: 4px;
            }
        """)
        
        layout.addWidget(self.status_label)
        layout.addStretch()
        layout.addWidget(self.progress_bar)
        
        self.setLayout(layout)
        
    def show_message(self, message, duration=0):
        self.status_label.setText(message)
        if duration > 0:
            QTimer.singleShot(duration * 1000, lambda: self.status_label.setText("Ready"))
            
    def show_progress(self, message, progress=None):
        self.status_label.setText(message)
        if progress is not None:
            self.progress_bar.setVisible(True)
            self.progress_bar.setValue(progress)
        else:
            self.progress_bar.setVisible(False)
            
    def hide_progress(self):
        self.progress_bar.setVisible(False)


class OCRWorker(QThread):
    result_ready = pyqtSignal(str, str, str)  # raw_text, processed_text, content_type
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)  # progress percentage
    
    def __init__(self, image, use_openai=False, api_key=None, model='gpt-4o', interview_mode=False):
        super().__init__()
        self.image = image
        self.use_openai = use_openai
        self.api_key = api_key
        self.model = model
        self.interview_mode = interview_mode
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def classify_content(self, text, interview_mode=False):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: –≤–æ–ø—Ä–æ—Å, –∑–∞–¥–∞—á–∞ –∏–ª–∏ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç"""
        text_lower = text.lower().strip()
        
        if interview_mode:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π
            
            # –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
            algo_keywords = [
                'algorithm', 'complexity', 'o(', 'big o', 'sort', 'search', 'tree', 'graph', 'array', 'list',
                '–∞–ª–≥–æ—Ä–∏—Ç–º', '—Å–ª–æ–∂–Ω–æ—Å—Ç—å', '—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞', '–ø–æ–∏—Å–∫', '–¥–µ—Ä–µ–≤–æ', '–≥—Ä–∞—Ñ', '–º–∞—Å—Å–∏–≤',
                'binary search', 'dfs', 'bfs', 'dynamic programming', 'recursion', 'fibonacci', 'factorial'
            ]
            if any(keyword in text_lower for keyword in algo_keywords):
                return "algorithm"
                
            # –ö–æ–¥-—Ä–µ–≤—å—é
            code_patterns = [
                r'def\s+\w+', r'function\s+\w+', r'class\s+\w+', r'for\s+\w+\s+in', r'while\s*\(',
                r'if\s*\(', r'return\s', r'import\s', r'#.*', r'//.*', r'/\*.*\*/'
            ]
            if any(re.search(pattern, text) for pattern in code_patterns):
                return "code_review"
                
            # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏
            logic_keywords = [
                'logic', 'puzzle', 'riddle', 'brain teaser', 'probability', 'combinatorics',
                '–ª–æ–≥–∏–∫–∞', '–≥–æ–ª–æ–≤–æ–ª–æ–º–∫–∞', '–∑–∞–≥–∞–¥–∫–∞', '–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', '–∫–æ–º–±–∏–Ω–∞—Ç–æ—Ä–∏–∫–∞'
            ]
            if any(keyword in text_lower for keyword in logic_keywords):
                return "logic_puzzle"
                
            # –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤
            math_prog_keywords = [
                'time complexity', 'space complexity', 'leetcode', 'hackerrank', 'codewars',
                '–≤—Ä–µ–º–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å', '–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å'
            ]
            if any(keyword in text_lower for keyword in math_prog_keywords):
                return "programming_task"
        
        # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–æ–ø—Ä–æ—Å—ã
        question_indicators = ['?', '—á—Ç–æ', '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫—Ç–æ', '—á–µ–º', 'what', 'how', 'where', 'when', 'why', 'who', 'which']
        if any(indicator in text_lower for indicator in question_indicators):
            return "question"
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–¥–∞—á–∏/–ø—Ä–∏–º–µ—Ä—ã
        task_indicators = ['—Ä–µ—à–∏—Ç—å', '–Ω–∞–π—Ç–∏', '–≤—ã—á–∏—Å–ª–∏—Ç—å', '–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å', 'calculate', 'solve', 'find', '=', '+', '-', '*', '/', 'x¬≤', '¬≤', '¬≥', '‚à´', '‚àë']
        if any(indicator in text_lower for indicator in task_indicators):
            return "task"
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
        math_patterns = [r'\d+\s*[+\-*/]\s*\d+', r'\d+\s*=', r'[a-z]\s*=', r'\(.*\)', r'\d+x', r'x\d+']
        for pattern in math_patterns:
            if re.search(pattern, text_lower):
                return "task"
                
        return "text"
        
    def process_with_ai(self, text, content_type, interview_mode=False):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é OpenAI –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        if self.cancelled:
            return text
            
        client = OpenAI(api_key=self.api_key)
        
        if interview_mode:
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π
            if content_type == "algorithm":
                system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏. –î–∞–π –ø–æ–ª–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏:
                1. –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
                2. –ü–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é (–±—Ä—É—Ç-—Ñ–æ—Ä—Å, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
                3. –ö–æ–¥ –Ω–∞ Python/JavaScript/Java (–ø–æ –≤—ã–±–æ—Ä—É)
                4. –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å O(n)
                5. –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                6. –ö—Ä–∞–π–Ω–∏–µ —Å–ª—É—á–∞–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                7. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã"""
                user_prompt = f"–†–µ—à–∏ —ç—Ç—É –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É –∫–∞–∫ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏: {text}"
                
            elif content_type == "code_review":
                system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∫–æ–¥-—Ä–µ–≤—å—é. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –∏ –¥–∞–π –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç:
                1. –û—à–∏–±–∫–∏ –∏ –±–∞–≥–∏
                2. –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                3. –ù–∞—Ä—É—à–µ–Ω–∏—è –ª—É—á—à–∏—Ö –ø—Ä–∞–∫—Ç–∏–∫
                4. –ü—Ä–æ–±–ª–µ–º—ã —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
                5. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
                6. –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∫–æ–¥–∞ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)"""
                user_prompt = f"–ü—Ä–æ–≤–µ–¥–∏ –∫–æ–¥-—Ä–µ–≤—å—é —ç—Ç–æ–≥–æ –∫–æ–¥–∞: {text}"
                
            elif content_type == "logic_puzzle":
                system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞—á–∞–º –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è—Ö. –†–µ—à–∏ –ª–æ–≥–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É:
                1. –ü–æ–Ω–∏–º–∞–Ω–∏–µ —É—Å–ª–æ–≤–∏–π –∑–∞–¥–∞—á–∏
                2. –õ–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –ø–æ—à–∞–≥–æ–≤–æ
                3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
                4. –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏ —Ä–µ—à–µ–Ω–∏—è"""
                user_prompt = f"–†–µ—à–∏ —ç—Ç—É –ª–æ–≥–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É –∫–∞–∫ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏: {text}"
                
            elif content_type == "programming_task":
                system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏. –†–µ—à–∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç—Å–∫—É—é –∑–∞–¥–∞—á—É:
                1. –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
                2. –ü–ª–∞–Ω —Ä–µ—à–µ–Ω–∏—è –∏ –∞–ª–≥–æ—Ä–∏—Ç–º
                3. –ö–æ–¥ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
                4. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                5. –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏
                6. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
                –ü–æ–∫–∞–∂–∏ –º—ã—à–ª–µ–Ω–∏–µ –∫–∞–∫ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏."""
                user_prompt = f"–†–µ—à–∏ —ç—Ç—É –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç—Å–∫—É—é –∑–∞–¥–∞—á—É –∫–∞–∫ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏: {text}"
                
            else:  # –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ —Ä–µ–∂–∏–º–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è
                system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏. –ü–æ–º–æ–≥–∏ –ø–æ–Ω—è—Ç—å –∏ –æ–±—ä—è—Å–Ω–∏—Ç—å –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π. 
                –î–∞–π –ø–æ–ª–Ω—ã–µ, –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –æ—Ç–≤–µ—Ç—ã —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏."""
                user_prompt = f"–û–±—ä—è—Å–Ω–∏ —ç—Ç–æ –∫–∞–∫ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏: {text}"
        
        else:
            # –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞
            if content_type == "question":
                system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã. –î–∞–π —Ç–æ—á–Ω—ã–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å. 
                –ï—Å–ª–∏ —ç—Ç–æ —É—á–µ–±–Ω—ã–π –≤–æ–ø—Ä–æ—Å, –æ–±—ä—è—Å–Ω–∏ —Ä–µ—à–µ–Ω–∏–µ –ø–æ—à–∞–≥–æ–≤–æ. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –≤–æ–ø—Ä–æ—Å."""
                user_prompt = f"–û—Ç–≤–µ—Ç—å –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å: {text}"
                
            elif content_type == "task":
                system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á. –†–µ—à–∏ –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ, –ø–æ–∫–∞–∂–∏ –≤—Å–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è. 
                –ï—Å–ª–∏ —ç—Ç–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞, –ø—Ä–æ–≤–µ—Ä—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ—à–µ–Ω–∏—è. –û–±—ä—è—Å–Ω–∏ –∫–∞–∂–¥—ã–π —à–∞–≥.
                –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ç–æ–º –∂–µ —è–∑—ã–∫–µ, —á—Ç–æ –∏ –∑–∞–¥–∞—á–∞."""
                user_prompt = f"–†–µ—à–∏ —ç—Ç—É –∑–∞–¥–∞—á—É: {text}"
                
            else:  # –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                system_prompt = """–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞. –ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ OCR, —É–ª—É—á—à–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, 
                —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º. –°–æ—Ö—Ä–∞–Ω–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Å–º—ã—Å–ª –∏ —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞."""
                user_prompt = f"–ò—Å–ø—Ä–∞–≤—å –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç: {text}"
            
        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        return response.choices[0].message.content.strip()
        
    def run(self):
        try:
            self.progress_updated.emit(10)
            if self.cancelled:
                return
                
            # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Tesseract –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è .,!?()[]{}":;+-=*/\\|_@#$%^&<>~`'
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ PSM —Ä–µ–∂–∏–º—ã –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            psm_modes = [6, 8, 7, 13]  # –†–∞–∑–Ω—ã–µ —Ä–µ–∂–∏–º—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            best_text = ""
            best_confidence = 0
            
            for psm in psm_modes:
                try:
                    config = f'--oem 3 --psm {psm}'
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –¥–∞–Ω–Ω—ã–µ –æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏
                    data = pytesseract.image_to_data(self.image, config=config, output_type=pytesseract.Output.DICT)
                    text = pytesseract.image_to_string(self.image, config=config)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω—é—é –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å
                    confidences = [int(conf) for conf in data['conf'] if int(conf) > 0]
                    avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç —Å –Ω–∞–∏–≤—ã—Å—à–µ–π –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å—é
                    if avg_confidence > best_confidence and text.strip():
                        best_confidence = avg_confidence
                        best_text = text.strip()
                        
                except Exception:
                    continue
            
            # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω —Ä–µ–∂–∏–º –Ω–µ –¥–∞–ª —Ö–æ—Ä–æ—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π
            if not best_text:
                try:
                    raw_text = pytesseract.image_to_string(self.image, config='--oem 3 --psm 6')
                except Exception:
                    raw_text = pytesseract.image_to_string(self.image)
            else:
                raw_text = best_text
                
            raw_text = raw_text.strip()
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
            if raw_text:
                # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
                raw_text = ' '.join(raw_text.split())
                # –£–±–∏—Ä–∞–µ–º –æ—á–µ–≤–∏–¥–Ω–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
                raw_text = ''.join(char for char in raw_text if ord(char) < 65536)
            
            self.progress_updated.emit(40)
            if self.cancelled:
                return
            
            if not raw_text:
                self.result_ready.emit("", "", "text")
                return
                
            content_type = self.classify_content(raw_text, self.interview_mode)
            
            self.progress_updated.emit(60)
            if self.cancelled:
                return
            
            if self.use_openai and self.api_key:
                try:
                    processed_text = self.process_with_ai(raw_text, content_type, self.interview_mode)
                    self.progress_updated.emit(100)
                    self.result_ready.emit(raw_text, processed_text, content_type)
                except Exception as e:
                    self.error_occurred.emit(f"OpenAI Error: {str(e)}")
                    self.result_ready.emit(raw_text, raw_text, content_type)
            else:
                self.progress_updated.emit(100)
                self.result_ready.emit(raw_text, raw_text, content_type)
                
        except Exception as e:
            self.error_occurred.emit(f"OCR Error: {str(e)}")


class AudioCaptureWorker(QThread):
    audio_captured = pyqtSignal(bytes)
    error_occurred = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.recording = False
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_duration = 3  # seconds
        
    def start_recording(self):
        self.recording = True
        self.start()
        
    def stop_recording(self):
        self.recording = False
        
    def run(self):
        try:
            chunk_size = self.sample_rate * self.chunk_duration
            
            while self.recording:
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ chunk
                audio_data = sd.rec(chunk_size, samplerate=self.sample_rate, 
                                  channels=self.channels, dtype=np.int16)
                sd.wait()  # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏
                
                if self.recording:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –µ—â–µ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ bytes
                    audio_bytes = audio_data.tobytes()
                    self.audio_captured.emit(audio_bytes)
                    
        except Exception as e:
            self.error_occurred.emit(f"Audio capture error: {str(e)}")


class TranscriptionWorker(QThread):
    transcription_ready = pyqtSignal(str, str)  # original_text, processed_text
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)
    
    def __init__(self, audio_data, settings, user_name=""):
        super().__init__()
        self.audio_data = audio_data
        self.settings = settings
        self.user_name = user_name
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def save_audio_temp(self, audio_data):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes –æ–±—Ä–∞—Ç–Ω–æ –≤ numpy array
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ WAV —Ñ–æ—Ä–º–∞—Ç
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16 bit = 2 bytes
            wf.setframerate(16000)
            wf.writeframes(audio_data)
        
        return temp_file.name
        
    def run(self):
        try:
            self.progress_updated.emit(20)
            if self.cancelled:
                return
                
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_audio_file = self.save_audio_temp(self.audio_data)
            
            self.progress_updated.emit(40)
            if self.cancelled:
                os.unlink(temp_audio_file)
                return
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI Whisper –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
            client = OpenAI(api_key=self.settings.get('api_key', ''))
            
            with open(temp_audio_file, 'rb') as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=self.settings.get('whisper_language', 'auto') if self.settings.get('whisper_language', 'auto') != 'auto' else None
                )
                
            self.progress_updated.emit(70)
            if self.cancelled:
                os.unlink(temp_audio_file)
                return
                
            original_text = transcript.text.strip()
            
            if not original_text:
                os.unlink(temp_audio_file)
                return
                
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é GPT
            processed_text = self.process_transcription(original_text)
            
            self.progress_updated.emit(100)
            self.transcription_ready.emit(original_text, processed_text)
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(temp_audio_file)
            
        except Exception as e:
            self.error_occurred.emit(f"Transcription error: {str(e)}")
            
    def process_transcription(self, text):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —á–µ—Ä–µ–∑ GPT"""
        if self.cancelled:
            return text
            
        if not self.settings.get('use_openai', False) or not self.settings.get('api_key'):
            return text
            
        try:
            client = OpenAI(api_key=self.settings.get('api_key'))
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–µ–∫—Å—Ç–µ
            user_mentioned = self.user_name and self.user_name.lower() in text.lower()
            
            # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫
            if user_mentioned:
                system_prompt = f"""
                –¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π. –í —Ç–µ–∫—Å—Ç–µ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è "{self.user_name}", 
                —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∫ –Ω–µ–º—É –æ–±—Ä–∞—â–∞—é—Ç—Å—è —Å –≤–æ–ø—Ä–æ—Å–æ–º –∏–ª–∏ –∑–∞–¥–∞—á–µ–π.
                
                –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
                1. –ü–µ—Ä–µ–≤–µ–¥–∏ –∏ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                2. –ï—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å –∫ {self.user_name}, –ø–æ–¥–≥–æ—Ç–æ–≤—å –∫—Ä–∞—Ç–∫–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –æ—Ç–≤–µ—Ç–æ–≤
                3. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
                
                –ü—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {self.settings.get('audio_prompt', '–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∏ —Å–¥–µ–ª–∞–π –µ–≥–æ –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º')}
                """
            else:
                system_prompt = f"""
                –¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–π. 
                
                –ü—Ä–æ–º–ø—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {self.settings.get('audio_prompt', '–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∏ —Å–¥–µ–ª–∞–π –µ–≥–æ –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º')}
                """
                
            response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–û–±—Ä–∞–±–æ—Ç–∞–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç: {text}"}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}\n\n–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: {text}"


class QuickResponseWorker(QThread):
    response_ready = pyqtSignal(str, str)  # ru_response, en_response
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)
    
    def __init__(self, question, settings, user_name=""):
        super().__init__()
        self.question = question
        self.settings = settings
        self.user_name = user_name
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def run(self):
        try:
            client = OpenAI(api_key=self.settings.get('api_key'))
            
            system_prompt = f"""
            –¢—ã –ø–æ–º–æ—â–Ω–∏–∫ {self.user_name if self.user_name else '–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è'} –Ω–∞ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏. 
            –î–∞–π –ö–†–ê–¢–ö–ò–ô (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.
            
            –û—Ç–≤–µ—á–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ –ø–æ –¥–µ–ª—É. –ï—Å–ª–∏ –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è, —É–∫–∞–∂–∏ —ç—Ç–æ.
            """
            
            self.progress_updated.emit(30)
            if self.cancelled:
                return
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
            ru_response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt + " –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                    {"role": "user", "content": self.question}
                ],
                temperature=0.3,
                max_tokens=150
            )
            
            self.progress_updated.emit(65)
            if self.cancelled:
                return
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
            en_response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt + " Respond in English."},
                    {"role": "user", "content": self.question}
                ],
                temperature=0.3,
                max_tokens=150
            )
            
            self.progress_updated.emit(100)
            
            ru_text = ru_response.choices[0].message.content.strip()
            en_text = en_response.choices[0].message.content.strip()
            
            self.response_ready.emit(ru_text, en_text)
            
        except Exception as e:
            self.error_occurred.emit(f"Response generation error: {str(e)}")


class SettingsDialog(QDialog):
    def __init__(self, parent=None, settings=None):
        super().__init__(parent)
        self.setWindowTitle("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ - Complete Assistant")
        self.setModal(True)
        self.settings = settings or {}
        self.setMinimumSize(600, 700)
        
        layout = QFormLayout()
        
        # OpenAI –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        openai_group = QGroupBox("OpenAI –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        openai_layout = QFormLayout()
        
        self.api_key_input = QLineEdit()
        self.api_key_input.setEchoMode(QLineEdit.Password)
        self.api_key_input.setText(self.settings.get('api_key', ''))
        openai_layout.addRow("OpenAI API Key:", self.api_key_input)
        
        # –ö–Ω–æ–ø–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API
        self.test_api_button = QPushButton("üîç –¢–µ—Å—Ç API")
        self.test_api_button.clicked.connect(self.test_api_connection)
        openai_layout.addRow("", self.test_api_button)
        
        self.use_openai_checkbox = QCheckBox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OpenAI –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        self.use_openai_checkbox.setChecked(self.settings.get('use_openai', False))
        openai_layout.addRow(self.use_openai_checkbox)
        
        self.model_combo = QComboBox()
        models = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo']
        self.model_combo.addItems(models)
        self.model_combo.setCurrentText(self.settings.get('model', 'gpt-4o'))
        openai_layout.addRow("OpenAI Model:", self.model_combo)
        
        openai_group.setLayout(openai_layout)
        layout.addRow(openai_group)
        
        # OCR –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        ocr_group = QGroupBox("OCR –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        ocr_layout = QFormLayout()
        
        self.language_combo = QComboBox()
        self.language_combo.addItems(['eng', 'rus', 'eng+rus', 'deu', 'fra', 'spa', 'ita'])
        self.language_combo.setCurrentText(self.settings.get('ocr_language', 'eng'))
        ocr_layout.addRow("OCR Language:", self.language_combo)
        
        self.preprocessing_checkbox = QCheckBox("–í–∫–ª—é—á–∏—Ç—å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        self.preprocessing_checkbox.setChecked(self.settings.get('preprocessing', True))
        ocr_layout.addRow(self.preprocessing_checkbox)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        quality_group = QGroupBox("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ OCR")
        quality_layout = QFormLayout()
        
        self.scale_factor_spin = QSpinBox()
        self.scale_factor_spin.setRange(1, 5)
        self.scale_factor_spin.setValue(self.settings.get('scale_factor', 3))
        self.scale_factor_spin.setToolTip("–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (1-5x)")
        quality_layout.addRow("–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:", self.scale_factor_spin)
        
        self.debug_images_checkbox = QCheckBox("–°–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        self.debug_images_checkbox.setChecked(self.settings.get('debug_images', False))
        self.debug_images_checkbox.setToolTip("–°–æ—Ö—Ä–∞–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫—É debug_images/")
        quality_layout.addRow(self.debug_images_checkbox)
        
        self.high_quality_checkbox = QCheckBox("–†–µ–∂–∏–º –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (–º–µ–¥–ª–µ–Ω–Ω–µ–µ)")
        self.high_quality_checkbox.setChecked(self.settings.get('high_quality_mode', False))
        self.high_quality_checkbox.setToolTip("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞")
        quality_layout.addRow(self.high_quality_checkbox)
        
        quality_group.setLayout(quality_layout)
        ocr_layout.addRow(quality_group)
        
        self.interview_mode_checkbox = QCheckBox("–†–µ–∂–∏–º –ø–æ–º–æ—â–Ω–∏–∫–∞ –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏")
        self.interview_mode_checkbox.setChecked(self.settings.get('interview_mode', False))
        ocr_layout.addRow(self.interview_mode_checkbox)
        
        ocr_group.setLayout(ocr_layout)
        layout.addRow(ocr_group)
        
        # –ê—É–¥–∏–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        audio_group = QGroupBox("–ê—É–¥–∏–æ –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
        audio_layout = QFormLayout()
        
        self.user_name_input = QLineEdit()
        self.user_name_input.setText(self.settings.get('user_name', ''))
        audio_layout.addRow("–í–∞—à–µ –∏–º—è:", self.user_name_input)
        
        self.whisper_language_combo = QComboBox()
        whisper_langs = ['auto', 'ru', 'en', 'de', 'fr', 'es', 'it', 'zh']
        self.whisper_language_combo.addItems(whisper_langs)
        self.whisper_language_combo.setCurrentText(self.settings.get('whisper_language', 'auto'))
        audio_layout.addRow("Whisper Language:", self.whisper_language_combo)
        
        audio_layout.addRow(QLabel("–ü—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ:"))
        self.audio_prompt_edit = QTextEdit()
        self.audio_prompt_edit.setMaximumHeight(100)
        default_prompt = "–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ), –∏—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏, —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º –∏ –≤—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã."
        self.audio_prompt_edit.setText(self.settings.get('audio_prompt', default_prompt))
        audio_layout.addRow(self.audio_prompt_edit)
        
        # –Ø–∑—ã–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        self.response_langs_group = QGroupBox("–Ø–∑—ã–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
        response_layout = QVBoxLayout()
        
        self.ru_response_checkbox = QCheckBox("–†—É—Å—Å–∫–∏–π")
        self.ru_response_checkbox.setChecked(self.settings.get('enable_ru_responses', True))
        response_layout.addWidget(self.ru_response_checkbox)
        
        self.en_response_checkbox = QCheckBox("English")
        self.en_response_checkbox.setChecked(self.settings.get('enable_en_responses', True))
        response_layout.addWidget(self.en_response_checkbox)
        
        self.response_langs_group.setLayout(response_layout)
        audio_layout.addRow(self.response_langs_group)
        
        audio_group.setLayout(audio_layout)
        layout.addRow(audio_group)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        ui_group = QGroupBox("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞")
        ui_layout = QFormLayout()
        
        self.floating_windows_checkbox = QCheckBox("–û—Ç–¥–µ–ª—å–Ω—ã–µ –ø–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞")
        self.floating_windows_checkbox.setChecked(self.settings.get('floating_windows', True))
        ui_layout.addRow(self.floating_windows_checkbox)
        
        self.autosave_checkbox = QCheckBox("–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏")
        self.autosave_checkbox.setChecked(self.settings.get('autosave_enabled', True))
        ui_layout.addRow(self.autosave_checkbox)
        
        self.log_level_combo = QComboBox()
        self.log_level_combo.addItems(['DEBUG', 'INFO', 'WARNING', 'ERROR'])
        self.log_level_combo.setCurrentText(self.settings.get('log_level', 'INFO'))
        ui_layout.addRow("–£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è:", self.log_level_combo)
        
        ui_group.setLayout(ui_layout)
        layout.addRow(ui_group)
        
        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addRow(buttons)
        
        self.setLayout(layout)
        
    def test_api_connection(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API"""
        api_key = self.api_key_input.text().strip()
        
        if not api_key:
            QMessageBox.warning(self, "–û—à–∏–±–∫–∞", "–í–≤–µ–¥–∏—Ç–µ API –∫–ª—é—á")
            return
            
        if not api_key.startswith('sk-'):
            QMessageBox.warning(self, "–û—à–∏–±–∫–∞", "API –∫–ª—é—á –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'sk-'")
            return
            
        try:
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            QMessageBox.information(self, "–£—Å–ø–µ—Ö", "‚úÖ API –∫–ª—é—á —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
        except Exception as e:
            QMessageBox.critical(self, "–û—à–∏–±–∫–∞", f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ API:\n{str(e)}")
        
    def get_settings(self):
        return {
            'api_key': self.api_key_input.text(),
            'use_openai': self.use_openai_checkbox.isChecked(),
            'model': self.model_combo.currentText(),
            'ocr_language': self.language_combo.currentText(),
            'preprocessing': self.preprocessing_checkbox.isChecked(),
            'scale_factor': self.scale_factor_spin.value(),
            'debug_images': self.debug_images_checkbox.isChecked(),
            'high_quality_mode': self.high_quality_checkbox.isChecked(),
            'interview_mode': self.interview_mode_checkbox.isChecked(),
            'user_name': self.user_name_input.text(),
            'whisper_language': self.whisper_language_combo.currentText(),
            'audio_prompt': self.audio_prompt_edit.toPlainText(),
            'enable_ru_responses': self.ru_response_checkbox.isChecked(),
            'enable_en_responses': self.en_response_checkbox.isChecked(),
            'floating_windows': self.floating_windows_checkbox.isChecked(),
            'autosave_enabled': self.autosave_checkbox.isChecked(),
            'log_level': self.log_level_combo.currentText()
        }


class VideoWidget(QLabel):
    selectionMade = pyqtSignal(QRectF)
    
    def __init__(self):
        super().__init__()
        self.setScaledContents(False)
        self.setMouseTracking(True)
        
        self.zoom_factor = 1.0
        self.pan_offset = QPointF(0, 0)
        self.is_panning = False
        self.last_mouse_pos = QPointF()
        
        self.is_selecting = False
        self.selection_start = QPointF()
        self.selection_end = QPointF()
        self.selection_rect = QRectF()
        
        self.video_size = None
        self.widget_size = None
        
        # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫–∏
        self.setToolTip("–õ–µ–≤–∞—è –∫–Ω–æ–ø–∫–∞: –≤—ã–¥–µ–ª–µ–Ω–∏–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è OCR\n–ü—Ä–∞–≤–∞—è –∫–Ω–æ–ø–∫–∞: –ø–∞–Ω–æ—Ä–∞–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n–ö–æ–ª–µ—Å–∏–∫–æ: –∑—É–º")
        self.setStyleSheet("""
            QLabel {
                border: 2px solid #3498db;
                border-radius: 8px;
                background-color: #ecf0f1;
            }
        """)
        
    def set_frame(self, frame):
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
        
        self.video_size = q_image.size()
        self.widget_size = self.size()
        
        pixmap = QPixmap.fromImage(q_image)
        
        scaled_width = int(width * self.zoom_factor)
        scaled_height = int(height * self.zoom_factor)
        scaled_pixmap = pixmap.scaled(scaled_width, scaled_height, Qt.KeepAspectRatio, Qt.SmoothTransformation)
        
        final_pixmap = QPixmap(self.size())
        final_pixmap.fill(Qt.black)
        
        painter = QPainter(final_pixmap)
        x = int((self.width() - scaled_width) / 2 + self.pan_offset.x())
        y = int((self.height() - scaled_height) / 2 + self.pan_offset.y())
        painter.drawPixmap(x, y, scaled_pixmap)
        
        if not self.selection_rect.isEmpty():
            painter.setPen(QPen(QColor(0, 255, 0), 3))
            painter.drawRect(self.selection_rect.toRect())
        
        painter.end()
        
        self.setPixmap(final_pixmap)
        
    def wheelEvent(self, event):
        old_zoom = self.zoom_factor
        
        if event.angleDelta().y() > 0:
            self.zoom_factor *= 1.1
        else:
            self.zoom_factor /= 1.1
            
        self.zoom_factor = max(0.1, min(self.zoom_factor, 10.0))
        
        mouse_pos = event.pos()
        zoom_change = self.zoom_factor / old_zoom
        
        center_x = self.width() / 2
        center_y = self.height() / 2
        
        offset_x = mouse_pos.x() - center_x - self.pan_offset.x()
        offset_y = mouse_pos.y() - center_y - self.pan_offset.y()
        
        self.pan_offset.setX(self.pan_offset.x() + offset_x * (1 - zoom_change))
        self.pan_offset.setY(self.pan_offset.y() + offset_y * (1 - zoom_change))
        
    def mousePressEvent(self, event):
        if event.button() == Qt.RightButton:
            self.is_panning = True
            self.last_mouse_pos = event.pos()
            self.setCursor(Qt.ClosedHandCursor)
        elif event.button() == Qt.LeftButton:
            self.is_selecting = True
            self.selection_start = event.pos()
            self.selection_end = event.pos()
            self.selection_rect = QRectF()
            
    def mouseMoveEvent(self, event):
        if self.is_panning:
            delta = event.pos() - self.last_mouse_pos
            self.pan_offset += delta
            self.last_mouse_pos = event.pos()
        elif self.is_selecting:
            self.selection_end = event.pos()
            self.selection_rect = QRectF(self.selection_start, self.selection_end).normalized()
            
    def mouseReleaseEvent(self, event):
        if event.button() == Qt.RightButton:
            self.is_panning = False
            self.setCursor(Qt.ArrowCursor)
        elif event.button() == Qt.LeftButton and self.is_selecting:
            self.is_selecting = False
            if not self.selection_rect.isEmpty():
                self.selectionMade.emit(self.selection_rect)
                
    def get_video_coords_from_widget(self, widget_point):
        if not self.video_size or not self.widget_size:
            return None
            
        scaled_width = self.video_size.width() * self.zoom_factor
        scaled_height = self.video_size.height() * self.zoom_factor
        
        x_offset = (self.width() - scaled_width) / 2 + self.pan_offset.x()
        y_offset = (self.height() - scaled_height) / 2 + self.pan_offset.y()
        
        video_x = (widget_point.x() - x_offset) / self.zoom_factor
        video_y = (widget_point.y() - y_offset) / self.zoom_factor
        
        return QPointF(video_x, video_y)


class OBSCompleteAssistantOptimized(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("OBS Complete Assistant - Optimized Version with Floating Windows")
        self.setGeometry(100, 100, 1400, 800)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self.setup_logging()
        
        # –í–∏–¥–µ–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self.cap = None
        self.current_frame = None
        self.ocr_worker = None
        self.history = []
        self.audio_history = []
        
        # –ê—É–¥–∏–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self.audio_worker = None
        self.transcription_worker = None
        self.response_worker = None
        self.is_recording = False
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self.settings = self.load_settings()
        self.session_start_time = datetime.now()
        self.last_autosave = datetime.now()
        
        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.last_ocr_hash = None
        self.performance_mode = False
        
        # –ü–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞
        self.response_window = None
        self.audio_window = None
        
        self.setup_ui()
        self.setup_floating_windows()
        self.setup_video_capture()
        self.setup_shortcuts()
        self.setup_timers()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
        self.check_audio_devices()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
        self.load_history_from_file()
        
        self.logger.info("Application started successfully")
        
    def setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"obs_assistant_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_floating_windows(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–≤–∞—é—â–∏—Ö –æ–∫–æ–Ω"""
        if self.settings.get('floating_windows', True):
            # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–≤–∞—é—â–µ–µ –æ–∫–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
            self.response_window = FloatingResponseWindow(self)
            self.response_window.generate_responses_requested.connect(self.generate_quick_responses_from_window)
            
            # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–≤–∞—é—â–µ–µ –æ–∫–Ω–æ –¥–ª—è –∞—É–¥–∏–æ
            self.audio_window = FloatingAudioWindow(self)
            self.audio_window.toggle_recording_requested.connect(self.toggle_recording)
            self.audio_window.save_audio_text_requested.connect(self.save_audio_text)
            
    def setup_shortcuts(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à"""
        # Ctrl+R - –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∑–∞–ø–∏—Å—å
        self.record_shortcut = QShortcut(QKeySequence("Ctrl+R"), self)
        self.record_shortcut.activated.connect(self.toggle_recording)
        
        # Ctrl+S - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        self.save_shortcut = QShortcut(QKeySequence("Ctrl+S"), self)
        self.save_shortcut.activated.connect(self.save_all_data)
        
        # Escape - –æ—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é
        self.cancel_shortcut = QShortcut(QKeySequence("Escape"), self)
        self.cancel_shortcut.activated.connect(self.cancel_current_operation)
        
        # F1 - –ø–æ–º–æ—â—å
        self.help_shortcut = QShortcut(QKeySequence("F1"), self)
        self.help_shortcut.activated.connect(self.show_help)
        
        # Ctrl+E - —ç–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö
        self.export_shortcut = QShortcut(QKeySequence("Ctrl+E"), self)
        self.export_shortcut.activated.connect(self.export_session_data)
        
        # Ctrl+1, Ctrl+2 - –ø–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞
        self.show_response_shortcut = QShortcut(QKeySequence("Ctrl+1"), self)
        self.show_response_shortcut.activated.connect(self.show_response_window)
        
        self.show_audio_shortcut = QShortcut(QKeySequence("Ctrl+2"), self)
        self.show_audio_shortcut.activated.connect(self.show_audio_window)
        
    def setup_timers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–µ—Ä–æ–≤"""
        # –¢–∞–π–º–µ—Ä –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π
        self.video_timer = QTimer()
        self.video_timer.timeout.connect(self.update_frame)
        self.video_timer.start(33)  # 30 FPS –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –¢–∞–π–º–µ—Ä –∞–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.autosave_timer = QTimer()
        self.autosave_timer.timeout.connect(self.autosave_data)
        self.autosave_timer.start(30000)  # 30 —Å–µ–∫—É–Ω–¥
        
        # –¢–∞–π–º–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.perf_timer = QTimer()
        self.perf_timer.timeout.connect(self.optimize_performance)
        self.perf_timer.start(5000)  # 5 —Å–µ–∫—É–Ω–¥
        
    def load_settings(self):
        load_dotenv()
        settings = {
            'api_key': os.getenv('OPENAI_API_KEY', ''),
            'use_openai': False,
            'model': 'gpt-4o',
            'ocr_language': 'eng',
            'preprocessing': True,
            'scale_factor': 3,
            'debug_images': False,
            'high_quality_mode': False,
            'interview_mode': False,
            'user_name': '',
            'whisper_language': 'auto',
            'audio_prompt': '–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ), –∏—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏, —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –±–æ–ª–µ–µ —á–∏—Ç–∞–µ–º—ã–º –∏ –≤—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã.',
            'enable_ru_responses': True,
            'enable_en_responses': True,
            'floating_windows': True,
            'autosave_enabled': True,
            'log_level': 'INFO'
        }
        
        settings_file = 'complete_settings_optimized.json'
        if os.path.exists(settings_file):
            try:
                with open(settings_file, 'r', encoding='utf-8') as f:
                    saved_settings = json.load(f)
                    settings.update(saved_settings)
            except Exception as e:
                print(f"Error loading settings: {e}")
                
        return settings
        
    def save_settings(self):
        settings_file = 'complete_settings_optimized.json'
        try:
            with open(settings_file, 'w', encoding='utf-8') as f:
                json.dump(self.settings, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"Error saving settings: {e}")
    
    def check_audio_devices(self):
        try:
            devices = sd.query_devices()
            input_devices = [d for d in devices if d['max_input_channels'] > 0]
            if not input_devices:
                self.status_widget.show_message("‚ö†Ô∏è No audio input devices found", 5)
                self.logger.warning("No audio input devices found")
            else:
                self.status_widget.show_message(f"‚úÖ Found {len(input_devices)} audio input device(s)", 3)
                self.logger.info(f"Found {len(input_devices)} audio input devices")
        except Exception as e:
            self.status_widget.show_message(f"‚ö†Ô∏è Audio check failed: {str(e)}", 5)
            self.logger.error(f"Audio check failed: {e}")
            
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # –°–æ–∑–¥–∞–µ–º –º–µ–Ω—é
        self.create_menu_bar()
        
        main_layout = QVBoxLayout()
        central_widget.setLayout(main_layout)
        
        # –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        controls_layout = QHBoxLayout()
        main_layout.addLayout(controls_layout)
        
        # –í–∏–¥–µ–æ –∫–Ω–æ–ø–∫–∏
        self.copy_button = QPushButton("üìã Copy OCR (Ctrl+C)")
        self.copy_button.clicked.connect(self.copy_ocr_text)
        self.copy_button.setEnabled(False)
        self.copy_button.setToolTip("–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞")
        self.copy_button.setStyleSheet("QPushButton { background-color: #3498db; color: white; }")
        controls_layout.addWidget(self.copy_button)
        
        self.reset_view_button = QPushButton("üîÑ Reset View")
        self.reset_view_button.clicked.connect(self.reset_view)
        self.reset_view_button.setToolTip("–°–±—Ä–æ—Å–∏—Ç—å –∑—É–º –∏ –ø–∞–Ω–æ—Ä–∞–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ")
        controls_layout.addWidget(self.reset_view_button)
        
        # –ê—É–¥–∏–æ –∫–Ω–æ–ø–∫–∏
        self.record_button = QPushButton("üé§ Start Recording (Ctrl+R)")
        self.record_button.clicked.connect(self.toggle_recording)
        self.record_button.setStyleSheet("QPushButton { font-size: 14px; padding: 10px; background-color: #27ae60; color: white; }")
        self.record_button.setToolTip("–ù–∞—á–∞—Ç—å/–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ")
        controls_layout.addWidget(self.record_button)
        
        # –ö–Ω–æ–ø–∫–∏ –ø–ª–∞–≤–∞—é—â–∏—Ö –æ–∫–æ–Ω
        self.show_response_btn = QPushButton("üí¨ Responses (Ctrl+1)")
        self.show_response_btn.clicked.connect(self.show_response_window)
        self.show_response_btn.setToolTip("–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
        self.show_response_btn.setStyleSheet("QPushButton { background-color: #e74c3c; color: white; }")
        controls_layout.addWidget(self.show_response_btn)
        
        self.show_audio_btn = QPushButton("üé§ Audio (Ctrl+2)")
        self.show_audio_btn.clicked.connect(self.show_audio_window)
        self.show_audio_btn.setToolTip("–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∞—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        self.show_audio_btn.setStyleSheet("QPushButton { background-color: #9b59b6; color: white; }")
        controls_layout.addWidget(self.show_audio_btn)
        
        # –ö–Ω–æ–ø–∫–∞ –æ—Ç–º–µ–Ω—ã
        self.cancel_button = QPushButton("‚ùå Cancel (Esc)")
        self.cancel_button.clicked.connect(self.cancel_current_operation)
        self.cancel_button.setEnabled(False)
        self.cancel_button.setToolTip("–û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é")
        self.cancel_button.setStyleSheet("QPushButton { background-color: #e67e22; color: white; }")
        controls_layout.addWidget(self.cancel_button)
        
        # –û–±—â–∏–µ –∫–Ω–æ–ø–∫–∏
        self.settings_button = QPushButton("‚öôÔ∏è Settings")
        self.settings_button.clicked.connect(self.open_settings)
        self.settings_button.setToolTip("–û—Ç–∫—Ä—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")
        controls_layout.addWidget(self.settings_button)
        
        controls_layout.addStretch()
        
        self.clear_button = QPushButton("üóëÔ∏è Clear All")
        self.clear_button.clicked.connect(self.clear_all_text)
        self.clear_button.setToolTip("–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ –∏—Å—Ç–æ—Ä–∏—é")
        self.clear_button.setStyleSheet("QPushButton { background-color: #95a5a6; color: white; }")
        controls_layout.addWidget(self.clear_button)
        
        # –°—Ç–∞—Ç—É—Å –≤–∏–¥–∂–µ—Ç
        self.status_widget = StatusWidget()
        main_layout.addWidget(self.status_widget)
        
        # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç - –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä
        main_splitter = QSplitter(Qt.Horizontal)
        main_layout.addWidget(main_splitter)
        
        # –õ–µ–≤–∞—è —á–∞—Å—Ç—å - –≤–∏–¥–µ–æ
        left_panel = QWidget()
        left_layout = QVBoxLayout()
        left_panel.setLayout(left_layout)
        
        video_label = QLabel("üìπ OBS Virtual Camera")
        video_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 14px; padding: 5px;")
        left_layout.addWidget(video_label)
        
        self.video_widget = VideoWidget()
        self.video_widget.selectionMade.connect(self.handle_selection)
        self.video_widget.setMinimumSize(640, 480)
        left_layout.addWidget(self.video_widget)
        
        main_splitter.addWidget(left_panel)
        
        # –ü—Ä–∞–≤–∞—è —á–∞—Å—Ç—å - OCR —Ä–µ–¥–∞–∫—Ç–æ—Ä
        right_panel = QWidget()
        right_layout = QVBoxLayout()
        right_panel.setLayout(right_layout)
        
        ocr_label = QLabel("üìù OCR Text Editor")
        ocr_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 14px; padding: 5px;")
        right_layout.addWidget(ocr_label)
        
        self.text_edit = QTextEdit()
        self.text_edit.setFont(QFont("Consolas", 11))
        self.text_edit.setPlaceholderText("–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å GPT-4o –æ—Ç–≤–µ—Ç–∞–º–∏ –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å...")
        self.text_edit.setStyleSheet("""
            QTextEdit {
                border: 2px solid #3498db;
                border-radius: 8px;
                background-color: #f8f9fa;
                padding: 10px;
            }
        """)
        right_layout.addWidget(self.text_edit)
        
        # –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è OCR —Ç–µ–∫—Å—Ç–æ–º
        text_buttons_layout = QHBoxLayout()
        right_layout.addLayout(text_buttons_layout)
        
        self.copy_text_button = QPushButton("üìã Copy Text")
        self.copy_text_button.clicked.connect(self.copy_text_from_editor)
        self.copy_text_button.setStyleSheet("QPushButton { background-color: #2ecc71; color: white; }")
        text_buttons_layout.addWidget(self.copy_text_button)
        
        self.save_text_button = QPushButton("üíæ Save OCR")
        self.save_text_button.clicked.connect(self.save_ocr_text)
        text_buttons_layout.addWidget(self.save_text_button)
        
        self.clear_text_button = QPushButton("üóëÔ∏è Clear")
        self.clear_text_button.clicked.connect(self.text_edit.clear)
        text_buttons_layout.addWidget(self.clear_text_button)
        
        text_buttons_layout.addStretch()
        
        main_splitter.addWidget(right_panel)
        
        # –ò—Å—Ç–æ—Ä–∏—è –≤ –Ω–∏–∂–Ω–µ–π —á–∞—Å—Ç–∏
        history_widget = QWidget()
        history_layout = QVBoxLayout()
        history_widget.setLayout(history_layout)
        
        history_label = QLabel("üìö Session History")
        history_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 12px; padding: 3px;")
        history_layout.addWidget(history_label)
        
        self.history_list = QListWidget()
        self.history_list.itemClicked.connect(self.load_history_item)
        self.history_list.setMaximumHeight(120)
        self.history_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #bdc3c7;
                border-radius: 5px;
                background-color: #ecf0f1;
            }
        """)
        history_layout.addWidget(self.history_list)
        
        history_buttons = QHBoxLayout()
        export_history_button = QPushButton("üì§ Export")
        export_history_button.clicked.connect(self.export_history)
        history_buttons.addWidget(export_history_button)
        
        clear_history_button = QPushButton("üóëÔ∏è Clear History")
        clear_history_button.clicked.connect(self.clear_history)
        history_buttons.addWidget(clear_history_button)
        
        history_buttons.addStretch()
        history_layout.addLayout(history_buttons)
        
        main_layout.addWidget(history_widget)
        
        main_splitter.setSizes([800, 600])
        
    def create_menu_bar(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        menubar = self.menuBar()
        
        # –§–∞–π–ª –º–µ–Ω—é
        file_menu = menubar.addMenu('–§–∞–π–ª')
        
        save_action = QAction('üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ (Ctrl+S)', self)
        save_action.setShortcut('Ctrl+S')
        save_action.triggered.connect(self.save_all_data)
        file_menu.addAction(save_action)
        
        export_action = QAction('üì§ –≠–∫—Å–ø–æ—Ä—Ç —Å–µ—Å—Å–∏–∏ (Ctrl+E)', self)
        export_action.setShortcut('Ctrl+E')
        export_action.triggered.connect(self.export_session_data)
        file_menu.addAction(export_action)
        
        file_menu.addSeparator()
        
        exit_action = QAction('‚ùå –í—ã—Ö–æ–¥', self)
        exit_action.triggered.connect(self.close)
        file_menu.addAction(exit_action)
        
        # –û–∫–Ω–∞ –º–µ–Ω—é
        windows_menu = menubar.addMenu('–û–∫–Ω–∞')
        
        show_response_action = QAction('üí¨ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã (Ctrl+1)', self)
        show_response_action.setShortcut('Ctrl+1')
        show_response_action.triggered.connect(self.show_response_window)
        windows_menu.addAction(show_response_action)
        
        show_audio_action = QAction('üé§ –ê—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (Ctrl+2)', self)
        show_audio_action.setShortcut('Ctrl+2')
        show_audio_action.triggered.connect(self.show_audio_window)
        windows_menu.addAction(show_audio_action)
        
        windows_menu.addSeparator()
        
        organize_windows_action = QAction('üìê –£–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –æ–∫–Ω–∞', self)
        organize_windows_action.triggered.connect(self.organize_windows)
        windows_menu.addAction(organize_windows_action)
        
        # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –º–µ–Ω—é
        tools_menu = menubar.addMenu('–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã')
        
        record_action = QAction('üé§ –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ (Ctrl+R)', self)
        record_action.setShortcut('Ctrl+R')
        record_action.triggered.connect(self.toggle_recording)
        tools_menu.addAction(record_action)
        
        cancel_action = QAction('‚ùå –û—Ç–º–µ–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏—é (Esc)', self)
        cancel_action.setShortcut('Esc')
        cancel_action.triggered.connect(self.cancel_current_operation)
        tools_menu.addAction(cancel_action)
        
        tools_menu.addSeparator()
        
        settings_action = QAction('‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏', self)
        settings_action.triggered.connect(self.open_settings)
        tools_menu.addAction(settings_action)
        
        # –ü–æ–º–æ—â—å –º–µ–Ω—é
        help_menu = menubar.addMenu('–ü–æ–º–æ—â—å')
        
        help_action = QAction('‚ùì –°–ø—Ä–∞–≤–∫–∞ (F1)', self)
        help_action.setShortcut('F1')
        help_action.triggered.connect(self.show_help)
        help_menu.addAction(help_action)
        
        about_action = QAction('‚ÑπÔ∏è –û –ø—Ä–æ–≥—Ä–∞–º–º–µ', self)
        about_action.triggered.connect(self.show_about)
        help_menu.addAction(about_action)
        
    def show_response_window(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤"""
        if self.response_window:
            self.response_window.show()
            self.response_window.raise_()
            self.response_window.activateWindow()
            self.status_widget.show_message("Response window opened", 2)
            
    def show_audio_window(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∞—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
        if self.audio_window:
            self.audio_window.show()
            self.audio_window.raise_()
            self.audio_window.activateWindow()
            self.status_widget.show_message("Audio window opened", 2)
            
    def organize_windows(self):
        """–£–ø–æ—Ä—è–¥–æ—á–∏—Ç—å –æ–∫–Ω–∞"""
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        
        # –ì–ª–∞–≤–Ω–æ–µ –æ–∫–Ω–æ —Å–ª–µ–≤–∞
        self.setGeometry(50, 50, 1000, 700)
        
        # –û–∫–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤ —Å–ø—Ä–∞–≤–∞ —Å–≤–µ—Ä—Ö—É
        if self.response_window:
            self.response_window.setGeometry(screen_rect.width() - 500, 50, 450, 400)
            self.response_window.show()
            
        # –û–∫–Ω–æ –∞—É–¥–∏–æ —Å–ø—Ä–∞–≤–∞ —Å–Ω–∏–∑—É
        if self.audio_window:
            self.audio_window.setGeometry(screen_rect.width() - 500, 470, 450, 400)
            self.audio_window.show()
            
        self.status_widget.show_message("Windows organized", 2)
        
    def setup_video_capture(self):
        for i in range(10):
            cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret:
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
                    cap.set(cv2.CAP_PROP_FPS, 30)
                    
                    backend = cap.getBackendName()
                    if "DSHOW" in backend or "DirectShow" in backend:
                        self.cap = cap
                        self.status_widget.show_message(f"Connected to camera {i}", 3)
                        self.logger.info(f"Connected to camera {i}")
                        break
                cap.release()
                
        if not self.cap:
            self.status_widget.show_message("No DirectShow camera found - Audio recording available", 5)
            self.logger.warning("No DirectShow camera found")
            
    def optimize_performance(self):
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        # –ï—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π, —Å–Ω–∏–∂–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–∏–¥–µ–æ
        active_operations = any([
            self.ocr_worker and self.ocr_worker.isRunning(),
            self.transcription_worker and self.transcription_worker.isRunning(),
            self.response_worker and self.response_worker.isRunning(),
            self.video_widget.is_selecting,
            self.video_widget.is_panning
        ])
        
        if not active_operations and not self.performance_mode:
            self.video_timer.setInterval(100)  # 10 FPS
            self.performance_mode = True
            self.logger.debug("Switched to performance mode (10 FPS)")
        elif active_operations and self.performance_mode:
            self.video_timer.setInterval(33)   # 30 FPS
            self.performance_mode = False
            self.logger.debug("Switched to normal mode (30 FPS)")
            
    def update_frame(self):
        if self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret:
                self.current_frame = frame
                self.video_widget.set_frame(frame)
                
    def handle_selection(self, rect):
        self.selected_rect = rect
        self.copy_button.setEnabled(True)
        self.cancel_button.setEnabled(True)
        self.status_widget.show_progress("Processing OCR with GPT-4o...", 0)
        self.process_ocr()
        
    def preprocess_image(self, image):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ OCR"""
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        scale_factor = self.settings.get('scale_factor', 3)
        high_quality = self.settings.get('high_quality_mode', False)
        height, width = image.shape[:2] if len(image.shape) == 3 else image.shape
        new_width = int(width * scale_factor)
        new_height = int(height * scale_factor)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º INTER_CUBIC –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏
        upscaled = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ
        if len(upscaled.shape) == 3:
            gray = cv2.cvtColor(upscaled, cv2.COLOR_BGR2GRAY)
        else:
            gray = upscaled
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º Gaussian blur –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —à—É–º–∞
        if high_quality:
            blurred = cv2.GaussianBlur(gray, (3, 3), 0)
        else:
            blurred = cv2.GaussianBlur(gray, (1, 1), 0)
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ–Ω–æ–π–∑–∏–Ω–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        if high_quality:
            # –ë–æ–ª–µ–µ —Å–∏–ª—å–Ω–∞—è –¥–µ–Ω–æ–π–∑–∏–Ω–≥ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            denoised = cv2.fastNlMeansDenoising(blurred, h=8, templateWindowSize=9, searchWindowSize=23)
        else:
            denoised = cv2.fastNlMeansDenoising(blurred, h=10, templateWindowSize=7, searchWindowSize=21)
        
        # –£–ª—É—á—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é CLAHE
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        enhanced = clahe.apply(denoised)
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–∞—Ö —Ç–µ–∫—Å—Ç–∞
        adaptive_thresh = cv2.adaptiveThreshold(
            enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–±—É–µ–º OTSU –º–µ—Ç–æ–¥
        _, otsu_thresh = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –±–µ–ª—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
        adaptive_white = np.sum(adaptive_thresh == 255)
        otsu_white = np.sum(otsu_thresh == 255)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –¥–∞–µ—Ç –±–æ–ª—å—à–µ –±–µ–ª—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π (–æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è —Ç–µ–∫—Å—Ç–∞)
        if adaptive_white > otsu_white:
            binary = adaptive_thresh
        else:
            binary = otsu_thresh
        
        # –ú–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        if high_quality:
            # –ë–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            kernel_small = np.ones((1, 1), np.uint8)
            kernel_medium = np.ones((2, 2), np.uint8)
            kernel_large = np.ones((3, 3), np.uint8)
            
            # –£–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å –º–µ–ª–∫–∏–π —à—É–º
            opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small, iterations=1)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –±—É–∫–≤–∞—Ö
            closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel_medium, iterations=2)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
            processed = cv2.morphologyEx(closing, cv2.MORPH_GRADIENT, kernel_large, iterations=1)
            processed = cv2.bitwise_or(closing, processed)
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
            processed = cv2.medianBlur(processed, 5)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            kernel = np.ones((2, 2), np.uint8)
            
            # –£–¥–∞–ª—è–µ–º –º–µ–ª–∫–∏–π —à—É–º
            opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –±—É–∫–≤–∞—Ö
            closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –æ—Ç –º–µ–ª–∫–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            processed = cv2.medianBlur(closing, 3)
        
        return processed
        
    def process_ocr(self):
        if self.current_frame is None or not hasattr(self, 'selected_rect'):
            return
            
        top_left = self.video_widget.get_video_coords_from_widget(self.selected_rect.topLeft())
        bottom_right = self.video_widget.get_video_coords_from_widget(self.selected_rect.bottomRight())
        
        if not top_left or not bottom_right:
            return
            
        x1 = max(0, int(top_left.x()))
        y1 = max(0, int(top_left.y()))
        x2 = min(self.current_frame.shape[1], int(bottom_right.x()))
        y2 = min(self.current_frame.shape[0], int(bottom_right.y()))
        
        if x2 <= x1 or y2 <= y1:
            self.status_widget.show_message("Invalid selection", 3)
            return
            
        roi = self.current_frame[y1:y2, x1:x2]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
        if roi.shape[0] < 20 or roi.shape[1] < 20:
            self.status_widget.show_message("Selection too small for OCR", 3)
            return
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        roi_hash = hash(roi.tobytes())
        if roi_hash == self.last_ocr_hash:
            self.status_widget.show_message("Using cached OCR result", 2)
            return
        self.last_ocr_hash = roi_hash
        
        if self.settings.get('preprocessing', True):
            processed_roi = self.preprocess_image(roi)
            pil_image = Image.fromarray(processed_roi)
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if self.settings.get('debug_images', False):
                try:
                    debug_dir = "debug_images"
                    os.makedirs(debug_dir, exist_ok=True)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    cv2.imwrite(f"{debug_dir}/original_{timestamp}.png", roi)
                    cv2.imwrite(f"{debug_dir}/processed_{timestamp}.png", processed_roi)
                    print(f"Debug images saved to {debug_dir}/")
                except Exception as e:
                    print(f"Failed to save debug images: {e}")
        else:
            # –î–∞–∂–µ –±–µ–∑ preprocessing –ø—Ä–∏–º–µ–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
            if len(roi.shape) == 3:
                rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
            else:
                rgb_roi = roi
                
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ö–æ—Ç—è –±—ã –≤ 2 —Ä–∞–∑–∞
            height, width = rgb_roi.shape[:2]
            upscaled = cv2.resize(rgb_roi, (width*2, height*2), interpolation=cv2.INTER_CUBIC)
            pil_image = Image.fromarray(upscaled)
            
        if self.settings.get('ocr_language', 'eng') != 'eng':
            pytesseract.pytesseract.tesseract_cmd = pytesseract.pytesseract.tesseract_cmd
            os.environ['TESSDATA_PREFIX'] = os.path.dirname(pytesseract.pytesseract.tesseract_cmd)
            
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        quality_info = []
        if self.settings.get('preprocessing', True):
            scale = self.settings.get('scale_factor', 3)
            quality_info.append(f"Scale: {scale}x")
            if self.settings.get('high_quality_mode', False):
                quality_info.append("HQ mode")
        
        status_msg = f"Processing OCR ({', '.join(quality_info) if quality_info else 'Standard'})..."
        self.status_widget.show_message(status_msg, 2)
        
        self.ocr_worker = OCRWorker(
            pil_image, 
            self.settings.get('use_openai', False),
            self.settings.get('api_key', ''),
            self.settings.get('model', 'gpt-4o'),
            self.settings.get('interview_mode', False)
        )
        self.ocr_worker.result_ready.connect(self.handle_ocr_result)
        self.ocr_worker.error_occurred.connect(self.handle_ocr_error)
        self.ocr_worker.progress_updated.connect(self.handle_ocr_progress)
        self.ocr_worker.start()
        
        self.logger.info("Started OCR processing with GPT-4o")
        
    @pyqtSlot(int)
    def handle_ocr_progress(self, progress):
        self.status_widget.show_progress(f"Processing OCR with GPT-4o... {progress}%", progress)
        
    @pyqtSlot(str, str, str)
    def handle_ocr_result(self, raw_text, processed_text, content_type):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        if processed_text:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —á—Ç–æ —ç—Ç–æ GPT-4o –æ—Ç–≤–µ—Ç
            display_text = f"ü§ñ GPT-4o Response [{content_type.upper()}]\n"
            display_text += "=" * 50 + "\n\n"
            
            if content_type != "text":
                display_text += f"üìù Original OCR Text:\n{raw_text}\n\n"
                display_text += "üîÑ " + "=" * 45 + "\n\n"
            
            display_text += f"‚ú® GPT-4o Analysis:\n{processed_text}"
            
            self.text_edit.setText(display_text)
            self.add_to_history(display_text, content_type)
            
            type_labels = {
                "question": "–í–æ–ø—Ä–æ—Å", "task": "–ó–∞–¥–∞—á–∞", "text": "–¢–µ–∫—Å—Ç",
                "algorithm": "–ê–ª–≥–æ—Ä–∏—Ç–º", "code_review": "–ö–æ–¥-—Ä–µ–≤—å—é", 
                "logic_puzzle": "–õ–æ–≥–∏–∫–∞", "programming_task": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"
            }
            self.status_widget.show_message(f"‚úÖ GPT-4o: {type_labels.get(content_type, '–¢–µ–∫—Å—Ç')} –æ–±—Ä–∞–±–æ—Ç–∞–Ω ({len(processed_text)} —Å–∏–º–≤–æ–ª–æ–≤)", 5)
            self.logger.info(f"OCR completed with GPT-4o: {content_type}, {len(processed_text)} characters")
        else:
            self.status_widget.show_message("OCR: –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω", 3)
            self.logger.warning("OCR: No text detected")
            
    @pyqtSlot(str)
    def handle_ocr_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        self.status_widget.show_message(f"OCR Error: {error_msg}", 10)
        self.logger.error(f"OCR Error: {error_msg}")
        self.show_error_dialog("OCR Error", error_msg)
        
    def add_to_history(self, text, content_type="text"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        preview = text[:80] + "..." if len(text) > 80 else text
        type_emoji = {
            "question": "‚ùì", "task": "üìù", "text": "üìÑ",
            "algorithm": "‚öôÔ∏è", "code_review": "üîç", 
            "logic_puzzle": "üß©", "programming_task": "üíª"
        }
        item_text = f"[{timestamp}] {type_emoji.get(content_type, 'üìÑ')} {preview}"
        
        self.history.append({
            'timestamp': timestamp,
            'text': text,
            'preview': preview,
            'type': content_type
        })
        
        self.history_list.insertItem(0, item_text)
        
        if self.history_list.count() > 100:
            self.history_list.takeItem(100)
            self.history.pop()
            
    def load_history_item(self, item):
        index = self.history_list.row(item)
        if 0 <= index < len(self.history):
            self.text_edit.setText(self.history[index]['text'])
            
    def clear_history(self):
        reply = QMessageBox.question(self, '–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ', 
                                   '–í—ã —É–≤–µ—Ä–µ–Ω—ã, —á—Ç–æ —Ö–æ—Ç–∏—Ç–µ –æ—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é?',
                                   QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.history.clear()
            self.history_list.clear()
            self.audio_history.clear()
            self.status_widget.show_message("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞", 3)
            self.logger.info("History cleared")
            
    def copy_ocr_text(self):
        text = self.text_edit.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_widget.show_message("GPT-4o OCR result copied to clipboard", 2)
            self.logger.info("OCR text copied to clipboard")
            
    def copy_text_from_editor(self):
        text = self.text_edit.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_widget.show_message("Text copied to clipboard", 2)
            self.logger.info("Text copied to clipboard")
            
    def reset_view(self):
        self.video_widget.zoom_factor = 1.0
        self.video_widget.pan_offset = QPointF(0, 0)
        self.video_widget.selection_rect = QRectF()
        self.copy_button.setEnabled(False)
        self.status_widget.show_message("View reset", 2)
        self.logger.info("View reset")
        
    # –ê—É–¥–∏–æ –º–µ—Ç–æ–¥—ã
    def toggle_recording(self):
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()
            
    def start_recording(self):
        if not self.settings.get('api_key'):
            self.show_error_dialog("Configuration Error", "Please configure OpenAI API key in Settings")
            return
            
        try:
            self.audio_worker = AudioCaptureWorker()
            self.audio_worker.audio_captured.connect(self.handle_audio_data)
            self.audio_worker.error_occurred.connect(self.handle_audio_error)
            
            self.audio_worker.start_recording()
            self.is_recording = True
            
            self.record_button.setText("‚èπÔ∏è Stop Recording (Ctrl+R)")
            self.record_button.setStyleSheet("QPushButton { background-color: #e74c3c; color: white; font-size: 14px; padding: 10px; }")
            self.status_widget.show_message("üî¥ Recording audio...")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ –∞—É–¥–∏–æ –æ–∫–Ω–µ
            if self.audio_window:
                self.audio_window.set_recording_state(True)
                
            self.logger.info("Audio recording started")
            
        except Exception as e:
            self.status_widget.show_message(f"Audio Error: {str(e)}", 10)
            self.logger.error(f"Audio recording error: {e}")
            self.show_error_dialog("Audio Error", str(e))
            
    def stop_recording(self):
        if self.audio_worker:
            self.audio_worker.stop_recording()
            self.audio_worker.wait(5000)  # –ñ–¥–µ–º –º–∞–∫—Å–∏–º—É–º 5 —Å–µ–∫—É–Ω–¥
            if self.audio_worker.isRunning():
                self.audio_worker.terminate()
            self.audio_worker = None
            
        self.is_recording = False
        self.record_button.setText("üé§ Start Recording (Ctrl+R)")
        self.record_button.setStyleSheet("QPushButton { font-size: 14px; padding: 10px; background-color: #27ae60; color: white; }")
        self.status_widget.show_message("Ready", 2)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ –∞—É–¥–∏–æ –æ–∫–Ω–µ
        if self.audio_window:
            self.audio_window.set_recording_state(False)
            
        self.logger.info("Audio recording stopped")
        
    @pyqtSlot(bytes)
    def handle_audio_data(self, audio_data):
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        self.transcription_worker = TranscriptionWorker(
            audio_data, 
            self.settings, 
            self.settings.get('user_name', '')
        )
        self.transcription_worker.transcription_ready.connect(self.handle_transcription)
        self.transcription_worker.error_occurred.connect(self.handle_transcription_error)
        self.transcription_worker.progress_updated.connect(self.handle_transcription_progress)
        self.transcription_worker.start()
        
        self.status_widget.show_progress("Processing audio...", 0)
        self.cancel_button.setEnabled(True)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –∞—É–¥–∏–æ –æ–∫–Ω–µ
        if self.audio_window:
            self.audio_window.set_status("üîÑ Processing audio...")
        
    @pyqtSlot(int)
    def handle_transcription_progress(self, progress):
        self.status_widget.show_progress(f"Processing audio... {progress}%", progress)
        
    @pyqtSlot(str, str)
    def handle_transcription(self, original_text, processed_text):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞—É–¥–∏–æ –æ–∫–Ω–æ
        if self.audio_window:
            self.audio_window.add_transcription(f"[{timestamp}] {original_text}")
            self.audio_window.add_processed_text(f"[{timestamp}] {processed_text}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞—É–¥–∏–æ –∏—Å—Ç–æ—Ä–∏—é
        self.audio_history.append({
            'timestamp': timestamp,
            'original': original_text,
            'processed': processed_text
        })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –ª–∏ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_name = self.settings.get('user_name', '')
        if user_name and user_name.lower() in original_text.lower():
            self.status_widget.show_message(f"üë§ Your name mentioned! Check Quick Responses", 5)
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –æ–∫–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã
            if self.response_window:
                self.response_window.set_question(original_text)
                self.response_window.show()
                self.response_window.raise_()
                self.generate_quick_responses_from_window(original_text)
        else:
            self.status_widget.show_message("üî¥ Recording audio...")
            
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –∞—É–¥–∏–æ –æ–∫–Ω–µ
        if self.audio_window:
            if user_name and user_name.lower() in original_text.lower():
                self.audio_window.set_status(f"üë§ Your name mentioned!")
            else:
                self.audio_window.set_status("üî¥ Recording...")
            
        self.logger.info(f"Audio transcribed: {len(original_text)} characters")
            
    @pyqtSlot(str)
    def handle_transcription_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        self.status_widget.show_message(f"Transcription Error: {error_msg}", 10)
        
        if self.audio_window:
            self.audio_window.set_status(f"‚ùå Error: {error_msg}")
            
        self.logger.error(f"Transcription Error: {error_msg}")
        self.show_error_dialog("Transcription Error", error_msg)
        
    @pyqtSlot(str)
    def handle_audio_error(self, error_msg):
        self.status_widget.show_message(f"Audio Error: {error_msg}", 10)
        
        if self.audio_window:
            self.audio_window.set_status(f"‚ùå Audio Error: {error_msg}")
            
        self.logger.error(f"Audio Error: {error_msg}")
        self.show_error_dialog("Audio Error", error_msg)
        self.stop_recording()
        
    def generate_quick_responses_from_window(self, question):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ –ø–ª–∞–≤–∞—é—â–µ–≥–æ –æ–∫–Ω–∞"""
        self.generate_quick_responses(question)
        
    def generate_quick_responses(self, question=None):
        if question is None:
            question = self.response_window.question_input.text().strip() if self.response_window else ""
            
        if not question:
            return
            
        if not self.settings.get('api_key'):
            if self.response_window:
                self.response_window.set_responses("‚ùå OpenAI API key not configured", "‚ùå OpenAI API key not configured")
            return
            
        self.response_worker = QuickResponseWorker(
            question, 
            self.settings, 
            self.settings.get('user_name', '')
        )
        self.response_worker.response_ready.connect(self.handle_responses)
        self.response_worker.error_occurred.connect(self.handle_response_error)
        self.response_worker.progress_updated.connect(self.handle_response_progress)
        self.response_worker.start()
        
        if self.response_window:
            self.response_window.set_status("üîÑ Generating GPT-4o responses...")
            
        self.status_widget.show_progress("Generating responses...", 0)
        self.cancel_button.setEnabled(True)
        
        self.logger.info("Started generating quick responses with GPT-4o")
        
    @pyqtSlot(int)
    def handle_response_progress(self, progress):
        self.status_widget.show_progress(f"Generating GPT-4o responses... {progress}%", progress)
        
    @pyqtSlot(str, str)
    def handle_responses(self, ru_response, en_response):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–∫–Ω–æ –æ—Ç–≤–µ—Ç–æ–≤
        if self.response_window:
            if self.settings.get('enable_ru_responses', True):
                final_ru = ru_response
            else:
                final_ru = "Russian responses disabled in settings"
                
            if self.settings.get('enable_en_responses', True):
                final_en = en_response
            else:
                final_en = "English responses disabled in settings"
                
            self.response_window.set_responses(final_ru, final_en)
            
        self.status_widget.show_message("‚úÖ GPT-4o responses generated", 3)
        self.logger.info("Quick responses generated successfully with GPT-4o")
            
    @pyqtSlot(str)
    def handle_response_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        if self.response_window:
            self.response_window.set_responses(f"‚ùå Error: {error_msg}", f"‚ùå Error: {error_msg}")
            
        self.logger.error(f"Response generation error: {error_msg}")
        self.show_error_dialog("Response Generation Error", error_msg)
        
    def cancel_current_operation(self):
        """–û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é"""
        cancelled_something = False
        
        if self.ocr_worker and self.ocr_worker.isRunning():
            self.ocr_worker.cancel()
            self.ocr_worker.quit()
            self.ocr_worker.wait(3000)
            cancelled_something = True
            self.logger.info("OCR operation cancelled")
            
        if self.transcription_worker and self.transcription_worker.isRunning():
            self.transcription_worker.cancel()
            self.transcription_worker.quit()
            self.transcription_worker.wait(3000)
            cancelled_something = True
            self.logger.info("Transcription operation cancelled")
            
        if self.response_worker and self.response_worker.isRunning():
            self.response_worker.cancel()
            self.response_worker.quit()
            self.response_worker.wait(3000)
            cancelled_something = True
            self.logger.info("Response generation cancelled")
            
        if cancelled_something:
            self.cancel_button.setEnabled(False)
            self.status_widget.hide_progress()
            self.status_widget.show_message("Operation cancelled", 3)
        else:
            self.status_widget.show_message("No operations to cancel", 2)
            
    def cleanup_workers(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö worker'–æ–≤"""
        workers = [self.ocr_worker, self.audio_worker, self.transcription_worker, self.response_worker]
        for worker in workers:
            if worker and worker.isRunning():
                worker.quit()
                worker.wait(5000)  # –ñ–¥–∞—Ç—å –º–∞–∫—Å–∏–º—É–º 5 —Å–µ–∫—É–Ω–¥
                if worker.isRunning():
                    worker.terminate()
                    
    def autosave_data(self):
        """–ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        if not self.settings.get('autosave_enabled', True):
            return
            
        try:
            self.save_history_to_file()
            self.save_settings()
            self.last_autosave = datetime.now()
            self.logger.debug("Autosave completed")
        except Exception as e:
            self.logger.error(f"Autosave failed: {e}")
            
    def save_all_data(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é"""
        try:
            self.save_history_to_file()
            self.save_settings()
            self.status_widget.show_message("All data saved successfully", 3)
            self.logger.info("Manual save completed")
        except Exception as e:
            self.status_widget.show_message(f"Save failed: {str(e)}", 5)
            self.logger.error(f"Manual save failed: {e}")
            self.show_error_dialog("Save Error", str(e))
            
    def save_history_to_file(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –≤ —Ñ–∞–π–ª"""
        history_dir = Path("history")
        history_dir.mkdir(exist_ok=True)
        
        history_file = history_dir / f'history_{datetime.now().strftime("%Y%m%d")}.json'
        
        data = {
            'session_start': self.session_start_time.isoformat(),
            'last_save': datetime.now().isoformat(),
            'ocr_history': self.history,
            'audio_history': self.audio_history
        }
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
            
    def load_history_from_file(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑ —Ñ–∞–π–ª–∞"""
        history_dir = Path("history")
        if not history_dir.exists():
            return
            
        history_file = history_dir / f'history_{datetime.now().strftime("%Y%m%d")}.json'
        
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                self.history = data.get('ocr_history', [])
                self.audio_history = data.get('audio_history', [])
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
                for item in self.history:
                    timestamp = item.get('timestamp', '')
                    type_emoji = {
                        "question": "‚ùì", "task": "üìù", "text": "üìÑ",
                        "algorithm": "‚öôÔ∏è", "code_review": "üîç", 
                        "logic_puzzle": "üß©", "programming_task": "üíª"
                    }
                    preview = item.get('preview', '')
                    content_type = item.get('type', 'text')
                    item_text = f"[{timestamp}] {type_emoji.get(content_type, 'üìÑ')} {preview}"
                    self.history_list.addItem(item_text)
                    
                self.logger.info(f"Loaded history: {len(self.history)} OCR items, {len(self.audio_history)} audio items")
                
            except Exception as e:
                self.logger.error(f"Failed to load history: {e}")
                
    def export_session_data(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏"""
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Export Session Data", 
                f"obs_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "JSON files (*.json)"
            )
            
            if filename:
                data = {
                    'session_start': self.session_start_time.isoformat(),
                    'export_time': datetime.now().isoformat(),
                    'settings': self.settings,
                    'ocr_history': self.history,
                    'audio_history': self.audio_history,
                    'current_ocr_text': self.text_edit.toPlainText()
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                    
                self.status_widget.show_message(f"Session data exported to {filename}", 5)
                self.logger.info(f"Session data exported to {filename}")
                
        except Exception as e:
            self.status_widget.show_message(f"Export failed: {str(e)}", 5)
            self.logger.error(f"Export failed: {e}")
            self.show_error_dialog("Export Error", str(e))
            
    def export_history(self):
        """–≠–∫—Å–ø–æ—Ä—Ç —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏–∏"""
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Export History", 
                f"obs_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "JSON files (*.json)"
            )
            
            if filename:
                data = {
                    'export_time': datetime.now().isoformat(),
                    'ocr_history': self.history,
                    'audio_history': self.audio_history
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                    
                self.status_widget.show_message(f"History exported to {filename}", 5)
                self.logger.info(f"History exported to {filename}")
                
        except Exception as e:
            self.show_error_dialog("Export Error", str(e))
            
    def save_ocr_text(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç OCR –≤ —Ñ–∞–π–ª"""
        text = self.text_edit.toPlainText()
        if not text:
            self.status_widget.show_message("No OCR text to save", 3)
            return
            
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save OCR Text", 
                f"gpt4o_ocr_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "Text files (*.txt)"
            )
            
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.status_widget.show_message(f"GPT-4o OCR text saved to {filename}", 3)
                
        except Exception as e:
            self.show_error_dialog("Save Error", str(e))
            
    def save_audio_text(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª"""
        if not self.audio_window:
            return
            
        text = self.audio_window.processed_area.toPlainText()
        if not text:
            self.status_widget.show_message("No audio text to save", 3)
            return
            
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save Audio Text", 
                f"audio_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "Text files (*.txt)"
            )
            
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.status_widget.show_message(f"Audio text saved to {filename}", 3)
                
        except Exception as e:
            self.show_error_dialog("Save Error", str(e))
            
    def show_error_dialog(self, title, message):
        """–ü–æ–∫–∞–∑–∞—Ç—å –¥–∏–∞–ª–æ–≥ –æ—à–∏–±–∫–∏"""
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Critical)
        msg.setWindowTitle(title)
        msg.setText(message)
        msg.exec_()
        
    def show_help(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É"""
        help_text = """
        <h2>OBS Complete Assistant - Optimized Version</h2>
        
        <h3>üéÆ –ì–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏:</h3>
        <ul>
        <li><b>Ctrl+C</b> - –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å OCR —Ç–µ–∫—Å—Ç</li>
        <li><b>Ctrl+R</b> - –ù–∞—á–∞—Ç—å/–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ</li>
        <li><b>Ctrl+S</b> - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ</li>
        <li><b>Ctrl+E</b> - –≠–∫—Å–ø–æ—Ä—Ç —Å–µ—Å—Å–∏–∏</li>
        <li><b>Ctrl+1</b> - –ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤</li>
        <li><b>Ctrl+2</b> - –ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∞—É–¥–∏–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏</li>
        <li><b>Esc</b> - –û—Ç–º–µ–Ω–∏—Ç—å —Ç–µ–∫—É—â—É—é –æ–ø–µ—Ä–∞—Ü–∏—é</li>
        <li><b>F1</b> - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É</li>
        </ul>
        
        <h3>ü™ü –ü–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞:</h3>
        <ul>
        <li><b>Response Window</b> - –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã —Å GPT-4o –Ω–∞ –¥–≤—É—Ö —è–∑—ã–∫–∞—Ö</li>
        <li><b>Audio Window</b> - –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏</li>
        <li>–û–∫–Ω–∞ –º–æ–∂–Ω–æ –∑–∞–∫—Ä–µ–ø–∏—Ç—å –ø–æ–≤–µ—Ä—Ö –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö</li>
        <li>–û–∫–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞—é—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ</li>
        </ul>
        
        <h3>ü§ñ GPT-4o –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è:</h3>
        <ul>
        <li>–í—Å–µ –æ—Ç–≤–µ—Ç—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é GPT-4o</li>
        <li>–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π</li>
        <li>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞</li>
        <li>–î–µ—Ç–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</li>
        </ul>
        
        <h3>üìπ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ:</h3>
        <ul>
        <li><b>–õ–µ–≤–∞—è –∫–Ω–æ–ø–∫–∞ –º—ã—à–∏</b> - –í—ã–¥–µ–ª–∏—Ç—å –æ–±–ª–∞—Å—Ç—å –¥–ª—è OCR</li>
        <li><b>–ü—Ä–∞–≤–∞—è –∫–Ω–æ–ø–∫–∞ –º—ã—à–∏ + –ø–µ—Ä–µ—Ç–∞—Å–∫–∏–≤–∞–Ω–∏–µ</b> - –ü–∞–Ω–æ—Ä–∞–º–∏—Ä–æ–≤–∞–Ω–∏–µ</li>
        <li><b>–ö–æ–ª–µ—Å–∏–∫–æ –º—ã—à–∏</b> - –ó—É–º</li>
        </ul>
        """
        
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setWindowTitle("–°–ø—Ä–∞–≤–∫–∞")
        msg.setText(help_text)
        msg.setTextFormat(Qt.RichText)
        msg.exec_()
        
    def show_about(self):
        """–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ"""
        about_text = f"""
        <h2>OBS Complete Assistant</h2>
        <p><b>Optimized Version with Floating Windows</b></p>
        <p>–í–µ—Ä—Å–∏—è: 3.0</p>
        <p>–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d')}</p>
        
        <p>–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ —Å:</p>
        <ul>
        <li>üìπ –ó–∞—Ö–≤–∞—Ç –≤–∏–¥–µ–æ –∏–∑ OBS Virtual Camera</li>
        <li>üìù OCR —Å GPT-4o –æ–±—Ä–∞–±–æ—Ç–∫–æ–π</li>
        <li>üé§ –ó–∞—Ö–≤–∞—Ç –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ</li>
        <li>üí¨ –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Ö</li>
        <li>ü™ü –û—Ç–¥–µ–ª—å–Ω—ã–µ –ø–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞</li>
        <li>üéØ –ü–æ–º–æ—â—å –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è—Ö</li>
        </ul>
        
        <p><b>–ù–æ–≤–æ–µ –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:</b></p>
        <ul>
        <li>ü™ü –û—Ç–¥–µ–ª—å–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π</li>
        <li>ü§ñ –ß–µ—Ç–∫–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ GPT-4o –æ—Ç–≤–µ—Ç–æ–≤</li>
        <li>‚ö° –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å</li>
        <li>üìå –ó–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –æ–∫–æ–Ω –ø–æ–≤–µ—Ä—Ö –≤—Å–µ—Ö</li>
        </ul>
        
        <p>–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏: PyQt5, OpenCV, Tesseract, OpenAI GPT-4o API</p>
        """
        
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setWindowTitle("–û –ø—Ä–æ–≥—Ä–∞–º–º–µ")
        msg.setText(about_text)
        msg.setTextFormat(Qt.RichText)
        msg.exec_()
        
    def open_settings(self):
        dialog = SettingsDialog(self, self.settings)
        if dialog.exec_():
            old_floating = self.settings.get('floating_windows', True)
            self.settings = dialog.get_settings()
            self.save_settings()
            self.status_widget.show_message("Settings updated", 3)
            self.logger.info("Settings updated")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            log_level = getattr(logging, self.settings.get('log_level', 'INFO'))
            logging.getLogger().setLevel(log_level)
            
            # –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–ª–∞–≤–∞—é—â–∏—Ö –æ–∫–æ–Ω
            new_floating = self.settings.get('floating_windows', True)
            if old_floating != new_floating:
                if new_floating and not self.response_window:
                    self.setup_floating_windows()
                elif not new_floating and self.response_window:
                    self.response_window.hide()
                    self.audio_window.hide()
            
    def clear_all_text(self):
        reply = QMessageBox.question(self, '–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ', 
                                   '–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç? –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ–ª—å–∑—è –æ—Ç–º–µ–Ω–∏—Ç—å.',
                                   QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.text_edit.clear()
            
            if self.response_window:
                self.response_window.ru_response_area.clear()
                self.response_window.en_response_area.clear()
                self.response_window.question_input.clear()
                
            if self.audio_window:
                self.audio_window.clear_all_text()
                
            self.status_widget.show_message("All text cleared", 3)
            self.logger.info("All text cleared")
        
    def keyPressEvent(self, event):
        if event.key() == Qt.Key_C and event.modifiers() == Qt.ControlModifier:
            self.copy_ocr_text()
            
    def closeEvent(self, event):
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∑–∞–∫—Ä—ã—Ç–∏–µ–º
        self.save_all_data()
        
        # –°–∫—Ä—ã–≤–∞–µ–º –ø–ª–∞–≤–∞—é—â–∏–µ –æ–∫–Ω–∞
        if self.response_window:
            self.response_window.hide()
        if self.audio_window:
            self.audio_window.hide()
        
        # –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
        if self.cap:
            self.cap.release()
        self.stop_recording()
        self.cleanup_workers()
        
        self.logger.info("Application closed")
        event.accept()


def main():
    app = QApplication(sys.argv)
    app.setApplicationName("OBS Complete Assistant Optimized")
    app.setApplicationVersion("3.0")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ sounddevice
    try:
        import sounddevice as sd
        print("‚úÖ sounddevice loaded successfully")
    except ImportError:
        print("‚ö†Ô∏è sounddevice not installed. Audio features will be limited.")
        print("Run: pip install sounddevice")
    
    window = OBSCompleteAssistantOptimized()
    window.show()
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –æ–∫–Ω–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    QTimer.singleShot(1000, window.organize_windows)
    
    try:
        sys.exit(app.exec_())
    except Exception as e:
        print(f"Application error: {e}")
        window.logger.error(f"Application error: {e}")


if __name__ == "__main__":
    main()
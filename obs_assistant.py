import sys
import cv2
import numpy as np
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, QPushButton, 
                           QLabel, QHBoxLayout, QTextEdit, QGroupBox, QLineEdit, 
                           QCheckBox, QSpinBox, QComboBox, QTabWidget, QListWidget,
                           QSplitter, QDialog, QDialogButtonBox, QFormLayout, QScrollArea,
                           QProgressBar, QMessageBox, QFileDialog, QMenuBar, QAction,
                           QSystemTrayIcon, QMenu, QShortcut, QToolTip, QDockWidget,
                           QDesktopWidget, QFrame)
from PyQt5.QtCore import Qt, QTimer, QRectF, QPointF, pyqtSignal, QThread, pyqtSlot, QSettings, QRect
from PyQt5.QtGui import QImage, QPixmap, QPainter, QPen, QColor, QFont, QKeySequence, QIcon
import pytesseract
import pyperclip
from PIL import Image
import os
from dotenv import load_dotenv
from openai import OpenAI
from datetime import datetime
import json
import sounddevice as sd
import tempfile
import requests
import wave
import re
import logging
import traceback
from pathlib import Path


class FloatingResponseWindow(QMainWindow):
    """ÐŸÐ»Ð°Ð²Ð°ÑŽÑ‰ÐµÐµ Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("ðŸ’¬ Quick Responses")
        self.setWindowFlags(Qt.Window | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_DeleteOnClose, False)  # ÐÐµ ÑƒÐ´Ð°Ð»ÑÑ‚ÑŒ Ð¿Ñ€Ð¸ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ð¸
        
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        self.setGeometry(screen_rect.width() - 500, 100, 480, 400)
        
        self.setup_ui()
        
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        central_widget.setLayout(layout)
        
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº
        title_label = QLabel("ðŸ’¬ Quick Responses")
        title_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50; padding: 10px;")
        title_label.setAlignment(Qt.AlignCenter)
        layout.addWidget(title_label)
        
        # ÐŸÐ¾Ð»Ðµ Ð´Ð»Ñ Ð²Ð²Ð¾Ð´Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ°
        question_layout = QHBoxLayout()
        self.question_input = QLineEdit()
        self.question_input.setPlaceholderText("Enter question to generate quick responses...")
        self.question_input.returnPressed.connect(self.generate_responses_signal)
        question_layout.addWidget(self.question_input)
        
        self.generate_btn = QPushButton("ðŸš€ Generate")
        self.generate_btn.clicked.connect(self.generate_responses_signal)
        question_layout.addWidget(self.generate_btn)
        
        layout.addLayout(question_layout)
        
        # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸
        self.status_label = QLabel("Ready to generate responses...")
        self.status_label.setStyleSheet("color: #7f8c8d; font-style: italic; padding: 5px;")
        layout.addWidget(self.status_label)
        
        # Ð ÑƒÑÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
        ru_group = QGroupBox("ðŸ‡·ðŸ‡º Russian Response")
        ru_layout = QVBoxLayout()
        
        self.ru_response_area = QTextEdit()
        self.ru_response_area.setMaximumHeight(120)
        self.ru_response_area.setFont(QFont("Consolas", 10))
        self.ru_response_area.setPlaceholderText("Ð ÑƒÑÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ Ð·Ð´ÐµÑÑŒ...")
        self.ru_response_area.setStyleSheet("QTextEdit { background-color: #f8f9fa; border: 1px solid #dee2e6; }")
        ru_layout.addWidget(self.ru_response_area)
        
        ru_buttons = QHBoxLayout()
        copy_ru_btn = QPushButton("ðŸ“‹ Copy RU")
        copy_ru_btn.clicked.connect(self.copy_ru_response)
        copy_ru_btn.setStyleSheet("QPushButton { background-color: #28a745; color: white; }")
        ru_buttons.addWidget(copy_ru_btn)
        ru_buttons.addStretch()
        ru_layout.addLayout(ru_buttons)
        
        ru_group.setLayout(ru_layout)
        layout.addWidget(ru_group)
        
        # ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚
        en_group = QGroupBox("ðŸ‡ºðŸ‡¸ English Response")
        en_layout = QVBoxLayout()
        
        self.en_response_area = QTextEdit()
        self.en_response_area.setMaximumHeight(120)
        self.en_response_area.setFont(QFont("Consolas", 10))
        self.en_response_area.setPlaceholderText("English response will appear here...")
        self.en_response_area.setStyleSheet("QTextEdit { background-color: #f8f9fa; border: 1px solid #dee2e6; }")
        en_layout.addWidget(self.en_response_area)
        
        en_buttons = QHBoxLayout()
        copy_en_btn = QPushButton("ðŸ“‹ Copy EN")
        copy_en_btn.clicked.connect(self.copy_en_response)
        copy_en_btn.setStyleSheet("QPushButton { background-color: #007bff; color: white; }")
        en_buttons.addWidget(copy_en_btn)
        en_buttons.addStretch()
        en_layout.addLayout(en_buttons)
        
        en_group.setLayout(en_layout)
        layout.addWidget(en_group)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¾ÐºÐ½Ð¾Ð¼
        control_layout = QHBoxLayout()
        
        self.pin_btn = QPushButton("ðŸ“Œ Pin")
        self.pin_btn.setCheckable(True)
        self.pin_btn.toggled.connect(self.toggle_pin)
        self.pin_btn.setToolTip("Ð—Ð°ÐºÑ€ÐµÐ¿Ð¸Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð¿Ð¾Ð²ÐµÑ€Ñ… Ð²ÑÐµÑ…")
        control_layout.addWidget(self.pin_btn)
        
        self.minimize_btn = QPushButton("âž– Minimize")
        self.minimize_btn.clicked.connect(self.showMinimized)
        control_layout.addWidget(self.minimize_btn)
        
        control_layout.addStretch()
        
        self.close_btn = QPushButton("âŒ Close")
        self.close_btn.clicked.connect(self.hide)
        self.close_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; }")
        control_layout.addWidget(self.close_btn)
        
        layout.addLayout(control_layout)
        
    def generate_responses_signal(self):
        """Ð¡Ð¸Ð³Ð½Ð°Ð» Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""
        self.generate_responses_requested.emit(self.question_input.text())
        
    generate_responses_requested = pyqtSignal(str)
    
    def set_responses(self, ru_text, en_text):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹"""
        self.ru_response_area.setText(ru_text)
        self.en_response_area.setText(en_text)
        self.status_label.setText("âœ… Responses generated successfully!")
        
    def set_status(self, status):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ"""
        self.status_label.setText(status)
        
    def set_question(self, question):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ"""
        self.question_input.setText(question)
        
    def copy_ru_response(self):
        """ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚"""
        text = self.ru_response_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("ðŸ“‹ Russian response copied!")
            
    def copy_en_response(self):
        """ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚"""
        text = self.en_response_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("ðŸ“‹ English response copied!")
            
    def toggle_pin(self, checked):
        """ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð·Ð°ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸Ðµ Ð¾ÐºÐ½Ð°"""
        if checked:
            self.setWindowFlags(self.windowFlags() | Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("ðŸ“Œ Pinned")
            self.pin_btn.setStyleSheet("QPushButton { background-color: #ffc107; }")
        else:
            self.setWindowFlags(self.windowFlags() & ~Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("ðŸ“Œ Pin")
            self.pin_btn.setStyleSheet("")
        self.show()
        
    def closeEvent(self, event):
        """ÐŸÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ - Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼"""
        event.ignore()
        self.hide()


class FloatingAudioWindow(QMainWindow):
    """ÐŸÐ»Ð°Ð²Ð°ÑŽÑ‰ÐµÐµ Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸"""
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("ðŸŽ¤ Audio Transcription")
        self.setWindowFlags(Qt.Window | Qt.WindowStaysOnTopHint)
        self.setAttribute(Qt.WA_DeleteOnClose, False)
        
        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        self.setGeometry(50, 100, 600, 500)
        
        self.setup_ui()
        
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        layout = QVBoxLayout()
        central_widget.setLayout(layout)
        
        # Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ñ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð°Ð¼Ð¸ Ð·Ð°Ð¿Ð¸ÑÐ¸
        header_layout = QHBoxLayout()
        
        title_label = QLabel("ðŸŽ¤ Audio Transcription")
        title_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50;")
        header_layout.addWidget(title_label)
        
        header_layout.addStretch()
        
        self.record_btn = QPushButton("ðŸŽ¤ Start Recording")
        self.record_btn.setStyleSheet("QPushButton { font-size: 14px; padding: 8px; }")
        self.record_btn.clicked.connect(self.toggle_recording_signal)
        header_layout.addWidget(self.record_btn)
        
        layout.addLayout(header_layout)
        
        # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð·Ð°Ð¿Ð¸ÑÐ¸
        self.status_label = QLabel("Ready to record")
        self.status_label.setStyleSheet("color: #7f8c8d; font-style: italic; padding: 5px;")
        layout.addWidget(self.status_label)
        
        # Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        transcription_group = QGroupBox("ðŸ“¢ Real-time Transcription")
        transcription_layout = QVBoxLayout()
        
        self.transcription_area = QTextEdit()
        self.transcription_area.setFont(QFont("Consolas", 11))
        self.transcription_area.setPlaceholderText("Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ Ð·Ð´ÐµÑÑŒ...")
        self.transcription_area.setStyleSheet("QTextEdit { background-color: #f0f0f0; border: 1px solid #ccc; }")
        transcription_layout.addWidget(self.transcription_area)
        
        transcription_group.setLayout(transcription_layout)
        layout.addWidget(transcription_group)
        
        # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
        processed_group = QGroupBox("ðŸ¤– Processed Text")
        processed_layout = QVBoxLayout()
        
        self.processed_area = QTextEdit()
        self.processed_area.setFont(QFont("Consolas", 11))
        self.processed_area.setPlaceholderText("ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ Ð·Ð´ÐµÑÑŒ...")
        self.processed_area.setStyleSheet("QTextEdit { background-color: #e8f5e8; border: 1px solid #28a745; }")
        processed_layout.addWidget(self.processed_area)
        
        processed_buttons = QHBoxLayout()
        copy_audio_btn = QPushButton("ðŸ“‹ Copy Audio")
        copy_audio_btn.clicked.connect(self.copy_processed_text)
        copy_audio_btn.setStyleSheet("QPushButton { background-color: #28a745; color: white; }")
        processed_buttons.addWidget(copy_audio_btn)
        
        save_audio_btn = QPushButton("ðŸ’¾ Save Audio")
        save_audio_btn.clicked.connect(self.save_audio_text_signal)
        processed_buttons.addWidget(save_audio_btn)
        
        processed_buttons.addStretch()
        processed_layout.addLayout(processed_buttons)
        
        processed_group.setLayout(processed_layout)
        layout.addWidget(processed_group)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¾ÐºÐ½Ð¾Ð¼
        control_layout = QHBoxLayout()
        
        self.pin_btn = QPushButton("ðŸ“Œ Pin")
        self.pin_btn.setCheckable(True)
        self.pin_btn.toggled.connect(self.toggle_pin)
        control_layout.addWidget(self.pin_btn)
        
        self.clear_btn = QPushButton("ðŸ—‘ï¸ Clear")
        self.clear_btn.clicked.connect(self.clear_all_text)
        control_layout.addWidget(self.clear_btn)
        
        control_layout.addStretch()
        
        self.close_btn = QPushButton("âŒ Close")
        self.close_btn.clicked.connect(self.hide)
        self.close_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; }")
        control_layout.addWidget(self.close_btn)
        
        layout.addLayout(control_layout)
        
    toggle_recording_requested = pyqtSignal()
    save_audio_text_requested = pyqtSignal()
    
    def toggle_recording_signal(self):
        """Ð¡Ð¸Ð³Ð½Ð°Ð» Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸"""
        self.toggle_recording_requested.emit()
        
    def save_audio_text_signal(self):
        """Ð¡Ð¸Ð³Ð½Ð°Ð» Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
        self.save_audio_text_requested.emit()
        
    def set_recording_state(self, is_recording):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸"""
        if is_recording:
            self.record_btn.setText("â¹ï¸ Stop Recording")
            self.record_btn.setStyleSheet("QPushButton { background-color: #dc3545; color: white; font-size: 14px; padding: 8px; }")
            self.status_label.setText("ðŸ”´ Recording...")
        else:
            self.record_btn.setText("ðŸŽ¤ Start Recording")
            self.record_btn.setStyleSheet("QPushButton { font-size: 14px; padding: 8px; }")
            self.status_label.setText("Ready to record")
            
    def add_transcription(self, text):
        """Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÑŽ"""
        self.transcription_area.append(text)
        
    def add_processed_text(self, text):
        """Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚"""
        self.processed_area.append(text)
        
    def set_status(self, status):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ð°Ñ‚ÑƒÑ"""
        self.status_label.setText(status)
        
    def copy_processed_text(self):
        """ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚"""
        text = self.processed_area.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_label.setText("ðŸ“‹ Processed text copied!")
            
    def clear_all_text(self):
        """ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚"""
        self.transcription_area.clear()
        self.processed_area.clear()
        self.status_label.setText("Text cleared")
        
    def toggle_pin(self, checked):
        """ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð·Ð°ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸Ðµ Ð¾ÐºÐ½Ð°"""
        if checked:
            self.setWindowFlags(self.windowFlags() | Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("ðŸ“Œ Pinned")
            self.pin_btn.setStyleSheet("QPushButton { background-color: #ffc107; }")
        else:
            self.setWindowFlags(self.windowFlags() & ~Qt.WindowStaysOnTopHint)
            self.pin_btn.setText("ðŸ“Œ Pin")
            self.pin_btn.setStyleSheet("")
        self.show()
        
    def closeEvent(self, event):
        """ÐŸÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ - Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼"""
        event.ignore()
        self.hide()


class StatusWidget(QWidget):
    """Ð£Ð»ÑƒÑ‡ÑˆÐµÐ½Ð½Ñ‹Ð¹ Ð²Ð¸Ð´Ð¶ÐµÑ‚ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€Ð¾Ð¼"""
    def __init__(self):
        super().__init__()
        layout = QHBoxLayout()
        
        self.status_label = QLabel("Ready")
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        self.progress_bar.setMaximumWidth(200)
        self.progress_bar.setStyleSheet("""
            QProgressBar {
                border: 1px solid #bdc3c7;
                border-radius: 5px;
                text-align: center;
            }
            QProgressBar::chunk {
                background-color: #3498db;
                border-radius: 4px;
            }
        """)
        
        layout.addWidget(self.status_label)
        layout.addStretch()
        layout.addWidget(self.progress_bar)
        
        self.setLayout(layout)
        
    def show_message(self, message, duration=0):
        self.status_label.setText(message)
        if duration > 0:
            QTimer.singleShot(duration * 1000, lambda: self.status_label.setText("Ready"))
            
    def show_progress(self, message, progress=None):
        self.status_label.setText(message)
        if progress is not None:
            self.progress_bar.setVisible(True)
            self.progress_bar.setValue(progress)
        else:
            self.progress_bar.setVisible(False)
            
    def hide_progress(self):
        self.progress_bar.setVisible(False)


class OCRWorker(QThread):
    result_ready = pyqtSignal(str, str, str)  # raw_text, processed_text, content_type
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)  # progress percentage
    
    def __init__(self, image, use_openai=False, api_key=None, model='gpt-4o', interview_mode=False):
        super().__init__()
        self.image = image
        self.use_openai = use_openai
        self.api_key = api_key
        self.model = model
        self.interview_mode = interview_mode
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def classify_content(self, text, interview_mode=False):
        """ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ñ‚Ð¸Ð¿ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°: Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¸Ð»Ð¸ Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚"""
        text_lower = text.lower().strip()
        
        if interview_mode:
            # Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° Ð´Ð»Ñ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹
            
            # ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
            algo_keywords = [
                'algorithm', 'complexity', 'o(', 'big o', 'sort', 'search', 'tree', 'graph', 'array', 'list',
                'Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼', 'ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ', 'ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°', 'Ð¿Ð¾Ð¸ÑÐº', 'Ð´ÐµÑ€ÐµÐ²Ð¾', 'Ð³Ñ€Ð°Ñ„', 'Ð¼Ð°ÑÑÐ¸Ð²',
                'binary search', 'dfs', 'bfs', 'dynamic programming', 'recursion', 'fibonacci', 'factorial'
            ]
            if any(keyword in text_lower for keyword in algo_keywords):
                return "algorithm"
                
            # ÐšÐ¾Ð´-Ñ€ÐµÐ²ÑŒÑŽ
            code_patterns = [
                r'def\s+\w+', r'function\s+\w+', r'class\s+\w+', r'for\s+\w+\s+in', r'while\s*\(',
                r'if\s*\(', r'return\s', r'import\s', r'#.*', r'//.*', r'/\*.*\*/'
            ]
            if any(re.search(pattern, text) for pattern in code_patterns):
                return "code_review"
                
            # Ð›Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
            logic_keywords = [
                'logic', 'puzzle', 'riddle', 'brain teaser', 'probability', 'combinatorics',
                'Ð»Ð¾Ð³Ð¸ÐºÐ°', 'Ð³Ð¾Ð»Ð¾Ð²Ð¾Ð»Ð¾Ð¼ÐºÐ°', 'Ð·Ð°Ð³Ð°Ð´ÐºÐ°', 'Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ', 'ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð°Ñ‚Ð¾Ñ€Ð¸ÐºÐ°'
            ]
            if any(keyword in text_lower for keyword in logic_keywords):
                return "logic_puzzle"
                
            # ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚Ð¾Ð²
            math_prog_keywords = [
                'time complexity', 'space complexity', 'leetcode', 'hackerrank', 'codewars',
                'Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ', 'Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ'
            ]
            if any(keyword in text_lower for keyword in math_prog_keywords):
                return "programming_task"
        
        # ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ°
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹
        question_indicators = ['?', 'Ñ‡Ñ‚Ð¾', 'ÐºÐ°Ðº', 'Ð³Ð´Ðµ', 'ÐºÐ¾Ð³Ð´Ð°', 'Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ', 'Ð·Ð°Ñ‡ÐµÐ¼', 'ÐºÑ‚Ð¾', 'Ñ‡ÐµÐ¼', 'what', 'how', 'where', 'when', 'why', 'who', 'which']
        if any(indicator in text_lower for indicator in question_indicators):
            return "question"
            
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð·Ð°Ð´Ð°Ñ‡Ð¸/Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹
        task_indicators = ['Ñ€ÐµÑˆÐ¸Ñ‚ÑŒ', 'Ð½Ð°Ð¹Ñ‚Ð¸', 'Ð²Ñ‹Ñ‡Ð¸ÑÐ»Ð¸Ñ‚ÑŒ', 'Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ñ‚ÑŒ', 'calculate', 'solve', 'find', '=', '+', '-', '*', '/', 'xÂ²', 'Â²', 'Â³', 'âˆ«', 'âˆ‘']
        if any(indicator in text_lower for indicator in task_indicators):
            return "task"
            
        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        math_patterns = [r'\d+\s*[+\-*/]\s*\d+', r'\d+\s*=', r'[a-z]\s*=', r'\(.*\)', r'\d+x', r'x\d+']
        for pattern in math_patterns:
            if re.search(pattern, text_lower):
                return "task"
                
        return "text"
        
    def process_with_ai(self, text, content_type, interview_mode=False):
        """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð° Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ OpenAI Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ñ‚Ð¸Ð¿Ð° ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°"""
        if self.cancelled:
            return text
            
        client = OpenAI(api_key=self.api_key)
        
        if interview_mode:
            # Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹ Ð´Ð»Ñ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹
            if content_type == "algorithm":
                system_prompt = """Ð¢Ñ‹ ÑÐºÑÐ¿ÐµÑ€Ñ‚-Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð¿Ð¾ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°Ð¼ Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸. Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸:
                1. ÐÐ½Ð°Ð»Ð¸Ð· Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹
                2. ÐŸÐ¾Ð´Ñ…Ð¾Ð´ Ðº Ñ€ÐµÑˆÐµÐ½Ð¸ÑŽ (Ð±Ñ€ÑƒÑ‚-Ñ„Ð¾Ñ€Ñ, Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ)
                3. ÐšÐ¾Ð´ Ð½Ð° Python/JavaScript/Java (Ð¿Ð¾ Ð²Ñ‹Ð±Ð¾Ñ€Ñƒ)
                4. Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ O(n)
                5. ÐŸÑ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ
                6. ÐšÑ€Ð°Ð¹Ð½Ð¸Ðµ ÑÐ»ÑƒÑ‡Ð°Ð¸ Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
                7. ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ñ‹"""
                user_prompt = f"Ð ÐµÑˆÐ¸ ÑÑ‚Ñƒ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÐºÐ°Ðº Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸: {text}"
                
            elif content_type == "code_review":
                system_prompt = """Ð¢Ñ‹ ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ ÐºÐ¾Ð´-Ñ€ÐµÐ²ÑŒÑŽ. ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÐºÐ¾Ð´ Ð¸ Ð´Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚:
                1. ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð±Ð°Ð³Ð¸
                2. ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
                3. ÐÐ°Ñ€ÑƒÑˆÐµÐ½Ð¸Ñ Ð»ÑƒÑ‡ÑˆÐ¸Ñ… Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ðº
                4. ÐŸÑ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ð¾ÑÑ‚Ð¸
                5. ÐŸÑ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸ÑŽ
                6. Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ ÐºÐ¾Ð´Ð° (ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾)"""
                user_prompt = f"ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸ ÐºÐ¾Ð´-Ñ€ÐµÐ²ÑŒÑŽ ÑÑ‚Ð¾Ð³Ð¾ ÐºÐ¾Ð´Ð°: {text}"
                
            elif content_type == "logic_puzzle":
                system_prompt = """Ð¢Ñ‹ ÑÐºÑÐ¿ÐµÑ€Ñ‚ Ð¿Ð¾ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¼ Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼ Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸ÑÑ…. Ð ÐµÑˆÐ¸ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ:
                1. ÐŸÐ¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÑƒÑÐ»Ð¾Ð²Ð¸Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ð¸
                2. Ð›Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ€Ð°ÑÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾
                3. ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ñ‹ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
                4. ÐžÐ±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð»Ð¾Ð³Ð¸ÐºÐ¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ"""
                user_prompt = f"Ð ÐµÑˆÐ¸ ÑÑ‚Ñƒ Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÐºÐ°Ðº Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸: {text}"
                
            elif content_type == "programming_task":
                system_prompt = """Ð¢Ñ‹ ÑÐºÑÐ¿ÐµÑ€Ñ‚-Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚ Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸. Ð ÐµÑˆÐ¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚ÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ:
                1. ÐŸÐ¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹
                2. ÐŸÐ»Ð°Ð½ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð¸ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼
                3. ÐšÐ¾Ð´ Ñ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÑÐ¼Ð¸
                4. ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ
                5. Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ðµ ÑÐ»ÑƒÑ‡Ð°Ð¸
                6. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº
                ÐŸÐ¾ÐºÐ°Ð¶Ð¸ Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð¸Ðµ ÐºÐ°Ðº Ð½Ð° Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸."""
                user_prompt = f"Ð ÐµÑˆÐ¸ ÑÑ‚Ñƒ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸ÑÑ‚ÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÐºÐ°Ðº Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸: {text}"
                
            else:  # Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² Ñ€ÐµÐ¶Ð¸Ð¼Ðµ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ
                system_prompt = """Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸. ÐŸÐ¾Ð¼Ð¾Ð³Ð¸ Ð¿Ð¾Ð½ÑÑ‚ÑŒ Ð¸ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚ÑŒ Ð»ÑŽÐ±Ñ‹Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹, ÑÐ²ÑÐ·Ð°Ð½Ð½Ñ‹Ðµ Ñ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼, Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸ÑÐ¼Ð¸, Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¾Ð¹. 
                Ð”Ð°Ð¹ Ð¿Ð¾Ð»Ð½Ñ‹Ðµ, Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ñ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð°Ð¼Ð¸."""
                user_prompt = f"ÐžÐ±ÑŠÑÑÐ½Ð¸ ÑÑ‚Ð¾ ÐºÐ°Ðº Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸: {text}"
        
        else:
            # ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ°
            if content_type == "question":
                system_prompt = """Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹. Ð”Ð°Ð¹ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ð¹, Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¸ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾Ñ. 
                Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ ÑƒÑ‡ÐµÐ±Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ, Ð¾Ð±ÑŠÑÑÐ½Ð¸ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ‚Ð¾Ð¼ Ð¶Ðµ ÑÐ·Ñ‹ÐºÐµ, Ñ‡Ñ‚Ð¾ Ð¸ Ð²Ð¾Ð¿Ñ€Ð¾Ñ."""
                user_prompt = f"ÐžÑ‚Ð²ÐµÑ‚ÑŒ Ð½Ð° ÑÑ‚Ð¾Ñ‚ Ð²Ð¾Ð¿Ñ€Ð¾Ñ: {text}"
                
            elif content_type == "task":
                system_prompt = """Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡. Ð ÐµÑˆÐ¸ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾, Ð¿Ð¾ÐºÐ°Ð¶Ð¸ Ð²ÑÐµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ñ. 
                Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ñ€ÐµÑˆÐµÐ½Ð¸Ñ. ÐžÐ±ÑŠÑÑÐ½Ð¸ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÑˆÐ°Ð³.
                ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ‚Ð¾Ð¼ Ð¶Ðµ ÑÐ·Ñ‹ÐºÐµ, Ñ‡Ñ‚Ð¾ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð°."""
                user_prompt = f"Ð ÐµÑˆÐ¸ ÑÑ‚Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ: {text}"
                
            else:  # Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚
                system_prompt = """Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð°. Ð˜ÑÐ¿Ñ€Ð°Ð²ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ OCR, ÑƒÐ»ÑƒÑ‡ÑˆÐ¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, 
                ÑÐ´ÐµÐ»Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¼. Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸ Ð¸ÑÑ…Ð¾Ð´Ð½Ñ‹Ð¹ ÑÐ¼Ñ‹ÑÐ» Ð¸ ÑÐ·Ñ‹Ðº Ñ‚ÐµÐºÑÑ‚Ð°."""
                user_prompt = f"Ð˜ÑÐ¿Ñ€Ð°Ð²ÑŒ Ð¸ Ð¾Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚: {text}"
            
        response = client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=4000
        )
        
        return response.choices[0].message.content.strip()
        
    def run(self):
        try:
            self.progress_updated.emit(10)
            if self.cancelled:
                return
                
            raw_text = pytesseract.image_to_string(self.image)
            raw_text = raw_text.strip()
            
            self.progress_updated.emit(40)
            if self.cancelled:
                return
            
            if not raw_text:
                self.result_ready.emit("", "", "text")
                return
                
            content_type = self.classify_content(raw_text, self.interview_mode)
            
            self.progress_updated.emit(60)
            if self.cancelled:
                return
            
            if self.use_openai and self.api_key:
                try:
                    processed_text = self.process_with_ai(raw_text, content_type, self.interview_mode)
                    self.progress_updated.emit(100)
                    self.result_ready.emit(raw_text, processed_text, content_type)
                except Exception as e:
                    self.error_occurred.emit(f"OpenAI Error: {str(e)}")
                    self.result_ready.emit(raw_text, raw_text, content_type)
            else:
                self.progress_updated.emit(100)
                self.result_ready.emit(raw_text, raw_text, content_type)
                
        except Exception as e:
            self.error_occurred.emit(f"OCR Error: {str(e)}")


class AudioCaptureWorker(QThread):
    audio_captured = pyqtSignal(bytes)
    error_occurred = pyqtSignal(str)
    
    def __init__(self):
        super().__init__()
        self.recording = False
        self.sample_rate = 16000
        self.channels = 1
        self.chunk_duration = 3  # seconds
        
    def start_recording(self):
        self.recording = True
        self.start()
        
    def stop_recording(self):
        self.recording = False
        
    def run(self):
        try:
            chunk_size = self.sample_rate * self.chunk_duration
            
            while self.recording:
                # Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ chunk
                audio_data = sd.rec(chunk_size, samplerate=self.sample_rate, 
                                  channels=self.channels, dtype=np.int16)
                sd.wait()  # Ð–Ð´ÐµÐ¼ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸
                
                if self.recording:  # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ ÐµÑ‰Ðµ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼
                    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² bytes
                    audio_bytes = audio_data.tobytes()
                    self.audio_captured.emit(audio_bytes)
                    
        except Exception as e:
            self.error_occurred.emit(f"Audio capture error: {str(e)}")


class TranscriptionWorker(QThread):
    transcription_ready = pyqtSignal(str, str)  # original_text, processed_text
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)
    
    def __init__(self, audio_data, settings, user_name=""):
        super().__init__()
        self.audio_data = audio_data
        self.settings = settings
        self.user_name = user_name
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def save_audio_temp(self, audio_data):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        
        # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ bytes Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð² numpy array
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² WAV Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # 16 bit = 2 bytes
            wf.setframerate(16000)
            wf.writeframes(audio_data)
        
        return temp_file.name
        
    def run(self):
        try:
            self.progress_updated.emit(20)
            if self.cancelled:
                return
                
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð²Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
            temp_audio_file = self.save_audio_temp(self.audio_data)
            
            self.progress_updated.emit(40)
            if self.cancelled:
                os.unlink(temp_audio_file)
                return
            
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ OpenAI Whisper Ð´Ð»Ñ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸
            client = OpenAI(api_key=self.settings.get('api_key', ''))
            
            with open(temp_audio_file, 'rb') as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language=self.settings.get('whisper_language', 'auto') if self.settings.get('whisper_language', 'auto') != 'auto' else None
                )
                
            self.progress_updated.emit(70)
            if self.cancelled:
                os.unlink(temp_audio_file)
                return
                
            original_text = transcript.text.strip()
            
            if not original_text:
                os.unlink(temp_audio_file)
                return
                
            # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ GPT
            processed_text = self.process_transcription(original_text)
            
            self.progress_updated.emit(100)
            self.transcription_ready.emit(original_text, processed_text)
            
            # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
            os.unlink(temp_audio_file)
            
        except Exception as e:
            self.error_occurred.emit(f"Transcription error: {str(e)}")
            
    def process_transcription(self, text):
        """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÑŽ Ñ‡ÐµÑ€ÐµÐ· GPT"""
        if self.cancelled:
            return text
            
        if not self.settings.get('use_openai', False) or not self.settings.get('api_key'):
            return text
            
        try:
            client = OpenAI(api_key=self.settings.get('api_key'))
            
            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ
            user_mentioned = self.user_name and self.user_name.lower() in text.lower()
            
            # Ð’Ñ‹Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐº
            if user_mentioned:
                system_prompt = f"""
                Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð° Ñ ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¹. Ð’ Ñ‚ÐµÐºÑÑ‚Ðµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ "{self.user_name}", 
                Ñ‡Ñ‚Ð¾ Ð¾Ð·Ð½Ð°Ñ‡Ð°ÐµÑ‚, Ñ‡Ñ‚Ð¾ Ðº Ð½ÐµÐ¼Ñƒ Ð¾Ð±Ñ€Ð°Ñ‰Ð°ÑŽÑ‚ÑÑ Ñ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼ Ð¸Ð»Ð¸ Ð·Ð°Ð´Ð°Ñ‡ÐµÐ¹.
                
                Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°:
                1. ÐŸÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ð¸ Ð¾Ñ‚Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐ¹ Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
                2. Ð•ÑÐ»Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ ÐµÑÑ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ Ðº {self.user_name}, Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
                3. Ð’Ñ‹Ð´ÐµÐ»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹
                
                ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {self.settings.get('audio_prompt', 'ÐŸÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð¸ ÑÐ´ÐµÐ»Ð°Ð¹ ÐµÐ³Ð¾ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¼')}
                """
            else:
                system_prompt = f"""
                Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ñ‚ÐµÐºÑÑ‚Ð° Ñ ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¹. 
                
                ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ: {self.settings.get('audio_prompt', 'ÐŸÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð¸ ÑÐ´ÐµÐ»Ð°Ð¹ ÐµÐ³Ð¾ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¼')}
                """
                
            response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð¹ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚: {text}"}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {str(e)}\n\nÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚: {text}"


class QuickResponseWorker(QThread):
    response_ready = pyqtSignal(str, str)  # ru_response, en_response
    error_occurred = pyqtSignal(str)
    progress_updated = pyqtSignal(int)
    
    def __init__(self, question, settings, user_name=""):
        super().__init__()
        self.question = question
        self.settings = settings
        self.user_name = user_name
        self.cancelled = False
        
    def cancel(self):
        self.cancelled = True
        
    def run(self):
        try:
            client = OpenAI(api_key=self.settings.get('api_key'))
            
            system_prompt = f"""
            Ð¢Ñ‹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº {self.user_name if self.user_name else 'Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ'} Ð½Ð° ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¸. 
            Ð”Ð°Ð¹ ÐšÐ ÐÐ¢ÐšÐ˜Ð™ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ) Ð½Ð¾ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð·Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ.
            
            ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ Ð¸ Ð¿Ð¾ Ð´ÐµÐ»Ñƒ. Ð•ÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ñ‹ ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ñ, ÑƒÐºÐ°Ð¶Ð¸ ÑÑ‚Ð¾.
            """
            
            self.progress_updated.emit(30)
            if self.cancelled:
                return
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼
            ru_response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt + " ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ."},
                    {"role": "user", "content": self.question}
                ],
                temperature=0.3,
                max_tokens=150
            )
            
            self.progress_updated.emit(65)
            if self.cancelled:
                return
            
            # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð½Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð¼
            en_response = client.chat.completions.create(
                model=self.settings.get('model', 'gpt-4o'),
                messages=[
                    {"role": "system", "content": system_prompt + " Respond in English."},
                    {"role": "user", "content": self.question}
                ],
                temperature=0.3,
                max_tokens=150
            )
            
            self.progress_updated.emit(100)
            
            ru_text = ru_response.choices[0].message.content.strip()
            en_text = en_response.choices[0].message.content.strip()
            
            self.response_ready.emit(ru_text, en_text)
            
        except Exception as e:
            self.error_occurred.emit(f"Response generation error: {str(e)}")


class SettingsDialog(QDialog):
    def __init__(self, parent=None, settings=None):
        super().__init__(parent)
        self.setWindowTitle("ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ - Complete Assistant")
        self.setModal(True)
        self.settings = settings or {}
        self.setMinimumSize(600, 700)
        
        layout = QFormLayout()
        
        # OpenAI Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
        openai_group = QGroupBox("OpenAI ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸")
        openai_layout = QFormLayout()
        
        self.api_key_input = QLineEdit()
        self.api_key_input.setEchoMode(QLineEdit.Password)
        self.api_key_input.setText(self.settings.get('api_key', ''))
        openai_layout.addRow("OpenAI API Key:", self.api_key_input)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ° Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ API
        self.test_api_button = QPushButton("ðŸ” Ð¢ÐµÑÑ‚ API")
        self.test_api_button.clicked.connect(self.test_api_connection)
        openai_layout.addRow("", self.test_api_button)
        
        self.use_openai_checkbox = QCheckBox("Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ OpenAI Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸")
        self.use_openai_checkbox.setChecked(self.settings.get('use_openai', False))
        openai_layout.addRow(self.use_openai_checkbox)
        
        self.model_combo = QComboBox()
        models = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo']
        self.model_combo.addItems(models)
        self.model_combo.setCurrentText(self.settings.get('model', 'gpt-4o'))
        openai_layout.addRow("OpenAI Model:", self.model_combo)
        
        openai_group.setLayout(openai_layout)
        layout.addRow(openai_group)
        
        # OCR Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
        ocr_group = QGroupBox("OCR ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸")
        ocr_layout = QFormLayout()
        
        self.language_combo = QComboBox()
        self.language_combo.addItems(['eng', 'rus', 'eng+rus', 'deu', 'fra', 'spa', 'ita'])
        self.language_combo.setCurrentText(self.settings.get('ocr_language', 'eng'))
        ocr_layout.addRow("OCR Language:", self.language_combo)
        
        self.preprocessing_checkbox = QCheckBox("Ð’ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹")
        self.preprocessing_checkbox.setChecked(self.settings.get('preprocessing', True))
        ocr_layout.addRow(self.preprocessing_checkbox)
        
        self.interview_mode_checkbox = QCheckBox("Ð ÐµÐ¶Ð¸Ð¼ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸ÐºÐ° Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¸")
        self.interview_mode_checkbox.setChecked(self.settings.get('interview_mode', False))
        ocr_layout.addRow(self.interview_mode_checkbox)
        
        ocr_group.setLayout(ocr_layout)
        layout.addRow(ocr_group)
        
        # ÐÑƒÐ´Ð¸Ð¾ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸
        audio_group = QGroupBox("ÐÑƒÐ´Ð¸Ð¾ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸")
        audio_layout = QFormLayout()
        
        self.user_name_input = QLineEdit()
        self.user_name_input.setText(self.settings.get('user_name', ''))
        audio_layout.addRow("Ð’Ð°ÑˆÐµ Ð¸Ð¼Ñ:", self.user_name_input)
        
        self.whisper_language_combo = QComboBox()
        whisper_langs = ['auto', 'ru', 'en', 'de', 'fr', 'es', 'it', 'zh']
        self.whisper_language_combo.addItems(whisper_langs)
        self.whisper_language_combo.setCurrentText(self.settings.get('whisper_language', 'auto'))
        audio_layout.addRow("Whisper Language:", self.whisper_language_combo)
        
        audio_layout.addRow(QLabel("ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾:"))
        self.audio_prompt_edit = QTextEdit()
        self.audio_prompt_edit.setMaximumHeight(100)
        default_prompt = "ÐŸÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº (ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾), Ð¸ÑÐ¿Ñ€Ð°Ð²ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸, ÑÐ´ÐµÐ»Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¼ Ð¸ Ð²Ñ‹Ð´ÐµÐ»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹."
        self.audio_prompt_edit.setText(self.settings.get('audio_prompt', default_prompt))
        audio_layout.addRow(self.audio_prompt_edit)
        
        # Ð¯Ð·Ñ‹ÐºÐ¸ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
        self.response_langs_group = QGroupBox("Ð¯Ð·Ñ‹ÐºÐ¸ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²")
        response_layout = QVBoxLayout()
        
        self.ru_response_checkbox = QCheckBox("Ð ÑƒÑÑÐºÐ¸Ð¹")
        self.ru_response_checkbox.setChecked(self.settings.get('enable_ru_responses', True))
        response_layout.addWidget(self.ru_response_checkbox)
        
        self.en_response_checkbox = QCheckBox("English")
        self.en_response_checkbox.setChecked(self.settings.get('enable_en_responses', True))
        response_layout.addWidget(self.en_response_checkbox)
        
        self.response_langs_group.setLayout(response_layout)
        audio_layout.addRow(self.response_langs_group)
        
        audio_group.setLayout(audio_layout)
        layout.addRow(audio_group)
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°
        ui_group = QGroupBox("ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°")
        ui_layout = QFormLayout()
        
        self.floating_windows_checkbox = QCheckBox("ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°")
        self.floating_windows_checkbox.setChecked(self.settings.get('floating_windows', True))
        ui_layout.addRow(self.floating_windows_checkbox)
        
        self.autosave_checkbox = QCheckBox("ÐÐ²Ñ‚Ð¾ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸")
        self.autosave_checkbox.setChecked(self.settings.get('autosave_enabled', True))
        ui_layout.addRow(self.autosave_checkbox)
        
        self.log_level_combo = QComboBox()
        self.log_level_combo.addItems(['DEBUG', 'INFO', 'WARNING', 'ERROR'])
        self.log_level_combo.setCurrentText(self.settings.get('log_level', 'INFO'))
        ui_layout.addRow("Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ:", self.log_level_combo)
        
        ui_group.setLayout(ui_layout)
        layout.addRow(ui_group)
        
        buttons = QDialogButtonBox(QDialogButtonBox.Ok | QDialogButtonBox.Cancel)
        buttons.accepted.connect(self.accept)
        buttons.rejected.connect(self.reject)
        layout.addRow(buttons)
        
        self.setLayout(layout)
        
    def test_api_connection(self):
        """Ð¢ÐµÑÑ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ðº OpenAI API"""
        api_key = self.api_key_input.text().strip()
        
        if not api_key:
            QMessageBox.warning(self, "ÐžÑˆÐ¸Ð±ÐºÐ°", "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ API ÐºÐ»ÑŽÑ‡")
            return
            
        if not api_key.startswith('sk-'):
            QMessageBox.warning(self, "ÐžÑˆÐ¸Ð±ÐºÐ°", "API ÐºÐ»ÑŽÑ‡ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ñ‚ÑŒÑÑ Ñ 'sk-'")
            return
            
        try:
            client = OpenAI(api_key=api_key)
            models = client.models.list()
            QMessageBox.information(self, "Ð£ÑÐ¿ÐµÑ…", "âœ… API ÐºÐ»ÑŽÑ‡ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾!")
        except Exception as e:
            QMessageBox.critical(self, "ÐžÑˆÐ¸Ð±ÐºÐ°", f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ Ðº API:\n{str(e)}")
        
    def get_settings(self):
        return {
            'api_key': self.api_key_input.text(),
            'use_openai': self.use_openai_checkbox.isChecked(),
            'model': self.model_combo.currentText(),
            'ocr_language': self.language_combo.currentText(),
            'preprocessing': self.preprocessing_checkbox.isChecked(),
            'interview_mode': self.interview_mode_checkbox.isChecked(),
            'user_name': self.user_name_input.text(),
            'whisper_language': self.whisper_language_combo.currentText(),
            'audio_prompt': self.audio_prompt_edit.toPlainText(),
            'enable_ru_responses': self.ru_response_checkbox.isChecked(),
            'enable_en_responses': self.en_response_checkbox.isChecked(),
            'floating_windows': self.floating_windows_checkbox.isChecked(),
            'autosave_enabled': self.autosave_checkbox.isChecked(),
            'log_level': self.log_level_combo.currentText()
        }


class VideoWidget(QLabel):
    selectionMade = pyqtSignal(QRectF)
    
    def __init__(self):
        super().__init__()
        self.setScaledContents(False)
        self.setMouseTracking(True)
        
        self.zoom_factor = 1.0
        self.pan_offset = QPointF(0, 0)
        self.is_panning = False
        self.last_mouse_pos = QPointF()
        
        self.is_selecting = False
        self.selection_start = QPointF()
        self.selection_end = QPointF()
        self.selection_rect = QRectF()
        
        self.video_size = None
        self.widget_size = None
        
        # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ¸
        self.setToolTip("Ð›ÐµÐ²Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°: Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ð´Ð»Ñ OCR\nÐŸÑ€Ð°Ð²Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°: Ð¿Ð°Ð½Ð¾Ñ€Ð°Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ\nÐšÐ¾Ð»ÐµÑÐ¸ÐºÐ¾: Ð·ÑƒÐ¼")
        self.setStyleSheet("""
            QLabel {
                border: 2px solid #3498db;
                border-radius: 8px;
                background-color: #ecf0f1;
            }
        """)
        
    def set_frame(self, frame):
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
        
        self.video_size = q_image.size()
        self.widget_size = self.size()
        
        pixmap = QPixmap.fromImage(q_image)
        
        scaled_width = int(width * self.zoom_factor)
        scaled_height = int(height * self.zoom_factor)
        scaled_pixmap = pixmap.scaled(scaled_width, scaled_height, Qt.KeepAspectRatio, Qt.SmoothTransformation)
        
        final_pixmap = QPixmap(self.size())
        final_pixmap.fill(Qt.black)
        
        painter = QPainter(final_pixmap)
        x = int((self.width() - scaled_width) / 2 + self.pan_offset.x())
        y = int((self.height() - scaled_height) / 2 + self.pan_offset.y())
        painter.drawPixmap(x, y, scaled_pixmap)
        
        if not self.selection_rect.isEmpty():
            painter.setPen(QPen(QColor(0, 255, 0), 3))
            painter.drawRect(self.selection_rect.toRect())
        
        painter.end()
        
        self.setPixmap(final_pixmap)
        
    def wheelEvent(self, event):
        old_zoom = self.zoom_factor
        
        if event.angleDelta().y() > 0:
            self.zoom_factor *= 1.1
        else:
            self.zoom_factor /= 1.1
            
        self.zoom_factor = max(0.1, min(self.zoom_factor, 10.0))
        
        mouse_pos = event.pos()
        zoom_change = self.zoom_factor / old_zoom
        
        center_x = self.width() / 2
        center_y = self.height() / 2
        
        offset_x = mouse_pos.x() - center_x - self.pan_offset.x()
        offset_y = mouse_pos.y() - center_y - self.pan_offset.y()
        
        self.pan_offset.setX(self.pan_offset.x() + offset_x * (1 - zoom_change))
        self.pan_offset.setY(self.pan_offset.y() + offset_y * (1 - zoom_change))
        
    def mousePressEvent(self, event):
        if event.button() == Qt.RightButton:
            self.is_panning = True
            self.last_mouse_pos = event.pos()
            self.setCursor(Qt.ClosedHandCursor)
        elif event.button() == Qt.LeftButton:
            self.is_selecting = True
            self.selection_start = event.pos()
            self.selection_end = event.pos()
            self.selection_rect = QRectF()
            
    def mouseMoveEvent(self, event):
        if self.is_panning:
            delta = event.pos() - self.last_mouse_pos
            self.pan_offset += delta
            self.last_mouse_pos = event.pos()
        elif self.is_selecting:
            self.selection_end = event.pos()
            self.selection_rect = QRectF(self.selection_start, self.selection_end).normalized()
            
    def mouseReleaseEvent(self, event):
        if event.button() == Qt.RightButton:
            self.is_panning = False
            self.setCursor(Qt.ArrowCursor)
        elif event.button() == Qt.LeftButton and self.is_selecting:
            self.is_selecting = False
            if not self.selection_rect.isEmpty():
                self.selectionMade.emit(self.selection_rect)
                
    def get_video_coords_from_widget(self, widget_point):
        if not self.video_size or not self.widget_size:
            return None
            
        scaled_width = self.video_size.width() * self.zoom_factor
        scaled_height = self.video_size.height() * self.zoom_factor
        
        x_offset = (self.width() - scaled_width) / 2 + self.pan_offset.x()
        y_offset = (self.height() - scaled_height) / 2 + self.pan_offset.y()
        
        video_x = (widget_point.x() - x_offset) / self.zoom_factor
        video_y = (widget_point.y() - y_offset) / self.zoom_factor
        
        return QPointF(video_x, video_y)


class OBSCompleteAssistantOptimized(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("OBS Complete Assistant - Optimized Version with Floating Windows")
        self.setGeometry(100, 100, 1400, 800)
        
        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        self.setup_logging()
        
        # Ð’Ð¸Ð´ÐµÐ¾ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
        self.cap = None
        self.current_frame = None
        self.ocr_worker = None
        self.history = []
        self.audio_history = []
        
        # ÐÑƒÐ´Ð¸Ð¾ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
        self.audio_worker = None
        self.transcription_worker = None
        self.response_worker = None
        self.is_recording = False
        
        # Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ
        self.settings = self.load_settings()
        self.session_start_time = datetime.now()
        self.last_autosave = datetime.now()
        
        # ÐŸÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        self.last_ocr_hash = None
        self.performance_mode = False
        
        # ÐŸÐ»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°
        self.response_window = None
        self.audio_window = None
        
        self.setup_ui()
        self.setup_floating_windows()
        self.setup_video_capture()
        self.setup_shortcuts()
        self.setup_timers()
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑÑ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²
        self.check_audio_devices()
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½ÑƒÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
        self.load_history_from_file()
        
        self.logger.info("Application started successfully")
        
    def setup_logging(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ"""
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        log_file = log_dir / f"obs_assistant_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_floating_windows(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð¾ÐºÐ¾Ð½"""
        if self.settings.get('floating_windows', True):
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰ÐµÐµ Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
            self.response_window = FloatingResponseWindow(self)
            self.response_window.generate_responses_requested.connect(self.generate_quick_responses_from_window)
            
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰ÐµÐµ Ð¾ÐºÐ½Ð¾ Ð´Ð»Ñ Ð°ÑƒÐ´Ð¸Ð¾
            self.audio_window = FloatingAudioWindow(self)
            self.audio_window.toggle_recording_requested.connect(self.toggle_recording)
            self.audio_window.save_audio_text_requested.connect(self.save_audio_text)
            
    def setup_shortcuts(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð³Ð¾Ñ€ÑÑ‡Ð¸Ñ… ÐºÐ»Ð°Ð²Ð¸Ñˆ"""
        # Ctrl+R - Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ
        self.record_shortcut = QShortcut(QKeySequence("Ctrl+R"), self)
        self.record_shortcut.activated.connect(self.toggle_recording)
        
        # Ctrl+S - ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        self.save_shortcut = QShortcut(QKeySequence("Ctrl+S"), self)
        self.save_shortcut.activated.connect(self.save_all_data)
        
        # Escape - Ð¾Ñ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑŽ
        self.cancel_shortcut = QShortcut(QKeySequence("Escape"), self)
        self.cancel_shortcut.activated.connect(self.cancel_current_operation)
        
        # F1 - Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ
        self.help_shortcut = QShortcut(QKeySequence("F1"), self)
        self.help_shortcut.activated.connect(self.show_help)
        
        # Ctrl+E - ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ…
        self.export_shortcut = QShortcut(QKeySequence("Ctrl+E"), self)
        self.export_shortcut.activated.connect(self.export_session_data)
        
        # Ctrl+1, Ctrl+2 - Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°
        self.show_response_shortcut = QShortcut(QKeySequence("Ctrl+1"), self)
        self.show_response_shortcut.activated.connect(self.show_response_window)
        
        self.show_audio_shortcut = QShortcut(QKeySequence("Ctrl+2"), self)
        self.show_audio_shortcut.activated.connect(self.show_audio_window)
        
    def setup_timers(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ‚Ð°Ð¹Ð¼ÐµÑ€Ð¾Ð²"""
        # Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ð²Ð½Ð¾Ð¹ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ð¾Ð¹
        self.video_timer = QTimer()
        self.video_timer.timeout.connect(self.update_frame)
        self.video_timer.start(33)  # 30 FPS Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
        
        # Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð°Ð²Ñ‚Ð¾ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
        self.autosave_timer = QTimer()
        self.autosave_timer.timeout.connect(self.autosave_data)
        self.autosave_timer.start(30000)  # 30 ÑÐµÐºÑƒÐ½Ð´
        
        # Ð¢Ð°Ð¹Ð¼ÐµÑ€ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸
        self.perf_timer = QTimer()
        self.perf_timer.timeout.connect(self.optimize_performance)
        self.perf_timer.start(5000)  # 5 ÑÐµÐºÑƒÐ½Ð´
        
    def load_settings(self):
        load_dotenv()
        settings = {
            'api_key': os.getenv('OPENAI_API_KEY', ''),
            'use_openai': False,
            'model': 'gpt-4o',
            'ocr_language': 'eng',
            'preprocessing': True,
            'interview_mode': False,
            'user_name': '',
            'whisper_language': 'auto',
            'audio_prompt': 'ÐŸÐµÑ€ÐµÐ²ÐµÐ´Ð¸ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº (ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾), Ð¸ÑÐ¿Ñ€Ð°Ð²ÑŒ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸, ÑÐ´ÐµÐ»Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð±Ð¾Ð»ÐµÐµ Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼Ñ‹Ð¼ Ð¸ Ð²Ñ‹Ð´ÐµÐ»Ð¸ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹.',
            'enable_ru_responses': True,
            'enable_en_responses': True,
            'floating_windows': True,
            'autosave_enabled': True,
            'log_level': 'INFO'
        }
        
        settings_file = 'complete_settings_optimized.json'
        if os.path.exists(settings_file):
            try:
                with open(settings_file, 'r', encoding='utf-8') as f:
                    saved_settings = json.load(f)
                    settings.update(saved_settings)
            except Exception as e:
                print(f"Error loading settings: {e}")
                
        return settings
        
    def save_settings(self):
        settings_file = 'complete_settings_optimized.json'
        try:
            with open(settings_file, 'w', encoding='utf-8') as f:
                json.dump(self.settings, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"Error saving settings: {e}")
    
    def check_audio_devices(self):
        try:
            devices = sd.query_devices()
            input_devices = [d for d in devices if d['max_input_channels'] > 0]
            if not input_devices:
                self.status_widget.show_message("âš ï¸ No audio input devices found", 5)
                self.logger.warning("No audio input devices found")
            else:
                self.status_widget.show_message(f"âœ… Found {len(input_devices)} audio input device(s)", 3)
                self.logger.info(f"Found {len(input_devices)} audio input devices")
        except Exception as e:
            self.status_widget.show_message(f"âš ï¸ Audio check failed: {str(e)}", 5)
            self.logger.error(f"Audio check failed: {e}")
            
    def setup_ui(self):
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼ÐµÐ½ÑŽ
        self.create_menu_bar()
        
        main_layout = QVBoxLayout()
        central_widget.setLayout(main_layout)
        
        # ÐŸÐ°Ð½ÐµÐ»ÑŒ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
        controls_layout = QHBoxLayout()
        main_layout.addLayout(controls_layout)
        
        # Ð’Ð¸Ð´ÐµÐ¾ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        self.copy_button = QPushButton("ðŸ“‹ Copy OCR (Ctrl+C)")
        self.copy_button.clicked.connect(self.copy_ocr_text)
        self.copy_button.setEnabled(False)
        self.copy_button.setToolTip("ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð² Ð±ÑƒÑ„ÐµÑ€ Ð¾Ð±Ð¼ÐµÐ½Ð°")
        self.copy_button.setStyleSheet("QPushButton { background-color: #3498db; color: white; }")
        controls_layout.addWidget(self.copy_button)
        
        self.reset_view_button = QPushButton("ðŸ”„ Reset View")
        self.reset_view_button.clicked.connect(self.reset_view)
        self.reset_view_button.setToolTip("Ð¡Ð±Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð·ÑƒÐ¼ Ð¸ Ð¿Ð°Ð½Ð¾Ñ€Ð°Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾")
        controls_layout.addWidget(self.reset_view_button)
        
        # ÐÑƒÐ´Ð¸Ð¾ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        self.record_button = QPushButton("ðŸŽ¤ Start Recording (Ctrl+R)")
        self.record_button.clicked.connect(self.toggle_recording)
        self.record_button.setStyleSheet("QPushButton { font-size: 14px; padding: 10px; background-color: #27ae60; color: white; }")
        self.record_button.setToolTip("ÐÐ°Ñ‡Ð°Ñ‚ÑŒ/Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð°ÑƒÐ´Ð¸Ð¾")
        controls_layout.addWidget(self.record_button)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ¸ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð¾ÐºÐ¾Ð½
        self.show_response_btn = QPushButton("ðŸ’¬ Responses (Ctrl+1)")
        self.show_response_btn.clicked.connect(self.show_response_window)
        self.show_response_btn.setToolTip("ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²")
        self.show_response_btn.setStyleSheet("QPushButton { background-color: #e74c3c; color: white; }")
        controls_layout.addWidget(self.show_response_btn)
        
        self.show_audio_btn = QPushButton("ðŸŽ¤ Audio (Ctrl+2)")
        self.show_audio_btn.clicked.connect(self.show_audio_window)
        self.show_audio_btn.setToolTip("ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸")
        self.show_audio_btn.setStyleSheet("QPushButton { background-color: #9b59b6; color: white; }")
        controls_layout.addWidget(self.show_audio_btn)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ° Ð¾Ñ‚Ð¼ÐµÐ½Ñ‹
        self.cancel_button = QPushButton("âŒ Cancel (Esc)")
        self.cancel_button.clicked.connect(self.cancel_current_operation)
        self.cancel_button.setEnabled(False)
        self.cancel_button.setToolTip("ÐžÑ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑŽ")
        self.cancel_button.setStyleSheet("QPushButton { background-color: #e67e22; color: white; }")
        controls_layout.addWidget(self.cancel_button)
        
        # ÐžÐ±Ñ‰Ð¸Ðµ ÐºÐ½Ð¾Ð¿ÐºÐ¸
        self.settings_button = QPushButton("âš™ï¸ Settings")
        self.settings_button.clicked.connect(self.open_settings)
        self.settings_button.setToolTip("ÐžÑ‚ÐºÑ€Ñ‹Ñ‚ÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ")
        controls_layout.addWidget(self.settings_button)
        
        controls_layout.addStretch()
        
        self.clear_button = QPushButton("ðŸ—‘ï¸ Clear All")
        self.clear_button.clicked.connect(self.clear_all_text)
        self.clear_button.setToolTip("ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚ Ð¸ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ")
        self.clear_button.setStyleSheet("QPushButton { background-color: #95a5a6; color: white; }")
        controls_layout.addWidget(self.clear_button)
        
        # Ð¡Ñ‚Ð°Ñ‚ÑƒÑ Ð²Ð¸Ð´Ð¶ÐµÑ‚
        self.status_widget = StatusWidget()
        main_layout.addWidget(self.status_widget)
        
        # ÐžÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ - Ð³Ð¾Ñ€Ð¸Ð·Ð¾Ð½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ¿Ð»Ð¸Ñ‚Ñ‚ÐµÑ€
        main_splitter = QSplitter(Qt.Horizontal)
        main_layout.addWidget(main_splitter)
        
        # Ð›ÐµÐ²Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ - Ð²Ð¸Ð´ÐµÐ¾
        left_panel = QWidget()
        left_layout = QVBoxLayout()
        left_panel.setLayout(left_layout)
        
        video_label = QLabel("ðŸ“¹ OBS Virtual Camera")
        video_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 14px; padding: 5px;")
        left_layout.addWidget(video_label)
        
        self.video_widget = VideoWidget()
        self.video_widget.selectionMade.connect(self.handle_selection)
        self.video_widget.setMinimumSize(640, 480)
        left_layout.addWidget(self.video_widget)
        
        main_splitter.addWidget(left_panel)
        
        # ÐŸÑ€Ð°Ð²Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ - OCR Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€
        right_panel = QWidget()
        right_layout = QVBoxLayout()
        right_panel.setLayout(right_layout)
        
        ocr_label = QLabel("ðŸ“ OCR Text Editor")
        ocr_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 14px; padding: 5px;")
        right_layout.addWidget(ocr_label)
        
        self.text_edit = QTextEdit()
        self.text_edit.setFont(QFont("Consolas", 11))
        self.text_edit.setPlaceholderText("Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ Ñ GPT-4o Ð¾Ñ‚Ð²ÐµÑ‚Ð°Ð¼Ð¸ Ð¿Ð¾ÑÐ²Ð¸Ñ‚ÑÑ Ð·Ð´ÐµÑÑŒ...")
        self.text_edit.setStyleSheet("""
            QTextEdit {
                border: 2px solid #3498db;
                border-radius: 8px;
                background-color: #f8f9fa;
                padding: 10px;
            }
        """)
        right_layout.addWidget(self.text_edit)
        
        # ÐšÐ½Ð¾Ð¿ÐºÐ¸ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ OCR Ñ‚ÐµÐºÑÑ‚Ð¾Ð¼
        text_buttons_layout = QHBoxLayout()
        right_layout.addLayout(text_buttons_layout)
        
        self.copy_text_button = QPushButton("ðŸ“‹ Copy Text")
        self.copy_text_button.clicked.connect(self.copy_text_from_editor)
        self.copy_text_button.setStyleSheet("QPushButton { background-color: #2ecc71; color: white; }")
        text_buttons_layout.addWidget(self.copy_text_button)
        
        self.save_text_button = QPushButton("ðŸ’¾ Save OCR")
        self.save_text_button.clicked.connect(self.save_ocr_text)
        text_buttons_layout.addWidget(self.save_text_button)
        
        self.clear_text_button = QPushButton("ðŸ—‘ï¸ Clear")
        self.clear_text_button.clicked.connect(self.text_edit.clear)
        text_buttons_layout.addWidget(self.clear_text_button)
        
        text_buttons_layout.addStretch()
        
        main_splitter.addWidget(right_panel)
        
        # Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð² Ð½Ð¸Ð¶Ð½ÐµÐ¹ Ñ‡Ð°ÑÑ‚Ð¸
        history_widget = QWidget()
        history_layout = QVBoxLayout()
        history_widget.setLayout(history_layout)
        
        history_label = QLabel("ðŸ“š Session History")
        history_label.setStyleSheet("font-weight: bold; color: #2c3e50; font-size: 12px; padding: 3px;")
        history_layout.addWidget(history_label)
        
        self.history_list = QListWidget()
        self.history_list.itemClicked.connect(self.load_history_item)
        self.history_list.setMaximumHeight(120)
        self.history_list.setStyleSheet("""
            QListWidget {
                border: 1px solid #bdc3c7;
                border-radius: 5px;
                background-color: #ecf0f1;
            }
        """)
        history_layout.addWidget(self.history_list)
        
        history_buttons = QHBoxLayout()
        export_history_button = QPushButton("ðŸ“¤ Export")
        export_history_button.clicked.connect(self.export_history)
        history_buttons.addWidget(export_history_button)
        
        clear_history_button = QPushButton("ðŸ—‘ï¸ Clear History")
        clear_history_button.clicked.connect(self.clear_history)
        history_buttons.addWidget(clear_history_button)
        
        history_buttons.addStretch()
        history_layout.addLayout(history_buttons)
        
        main_layout.addWidget(history_widget)
        
        main_splitter.setSizes([800, 600])
        
    def create_menu_bar(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÐµÐ½ÑŽ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ"""
        menubar = self.menuBar()
        
        # Ð¤Ð°Ð¹Ð» Ð¼ÐµÐ½ÑŽ
        file_menu = menubar.addMenu('Ð¤Ð°Ð¹Ð»')
        
        save_action = QAction('ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ (Ctrl+S)', self)
        save_action.setShortcut('Ctrl+S')
        save_action.triggered.connect(self.save_all_data)
        file_menu.addAction(save_action)
        
        export_action = QAction('ðŸ“¤ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑÐ¸Ð¸ (Ctrl+E)', self)
        export_action.setShortcut('Ctrl+E')
        export_action.triggered.connect(self.export_session_data)
        file_menu.addAction(export_action)
        
        file_menu.addSeparator()
        
        exit_action = QAction('âŒ Ð’Ñ‹Ñ…Ð¾Ð´', self)
        exit_action.triggered.connect(self.close)
        file_menu.addAction(exit_action)
        
        # ÐžÐºÐ½Ð° Ð¼ÐµÐ½ÑŽ
        windows_menu = menubar.addMenu('ÐžÐºÐ½Ð°')
        
        show_response_action = QAction('ðŸ’¬ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ (Ctrl+1)', self)
        show_response_action.setShortcut('Ctrl+1')
        show_response_action.triggered.connect(self.show_response_window)
        windows_menu.addAction(show_response_action)
        
        show_audio_action = QAction('ðŸŽ¤ ÐÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ (Ctrl+2)', self)
        show_audio_action.setShortcut('Ctrl+2')
        show_audio_action.triggered.connect(self.show_audio_window)
        windows_menu.addAction(show_audio_action)
        
        windows_menu.addSeparator()
        
        organize_windows_action = QAction('ðŸ“ Ð£Ð¿Ð¾Ñ€ÑÐ´Ð¾Ñ‡Ð¸Ñ‚ÑŒ Ð¾ÐºÐ½Ð°', self)
        organize_windows_action.triggered.connect(self.organize_windows)
        windows_menu.addAction(organize_windows_action)
        
        # Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¼ÐµÐ½ÑŽ
        tools_menu = menubar.addMenu('Ð˜Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ñ‹')
        
        record_action = QAction('ðŸŽ¤ Ð—Ð°Ð¿Ð¸ÑÑŒ Ð°ÑƒÐ´Ð¸Ð¾ (Ctrl+R)', self)
        record_action.setShortcut('Ctrl+R')
        record_action.triggered.connect(self.toggle_recording)
        tools_menu.addAction(record_action)
        
        cancel_action = QAction('âŒ ÐžÑ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑŽ (Esc)', self)
        cancel_action.setShortcut('Esc')
        cancel_action.triggered.connect(self.cancel_current_operation)
        tools_menu.addAction(cancel_action)
        
        tools_menu.addSeparator()
        
        settings_action = QAction('âš™ï¸ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸', self)
        settings_action.triggered.connect(self.open_settings)
        tools_menu.addAction(settings_action)
        
        # ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ Ð¼ÐµÐ½ÑŽ
        help_menu = menubar.addMenu('ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ')
        
        help_action = QAction('â“ Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° (F1)', self)
        help_action.setShortcut('F1')
        help_action.triggered.connect(self.show_help)
        help_menu.addAction(help_action)
        
        about_action = QAction('â„¹ï¸ Ðž Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ðµ', self)
        about_action.triggered.connect(self.show_about)
        help_menu.addAction(about_action)
        
    def show_response_window(self):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""
        if self.response_window:
            self.response_window.show()
            self.response_window.raise_()
            self.response_window.activateWindow()
            self.status_widget.show_message("Response window opened", 2)
            
    def show_audio_window(self):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸"""
        if self.audio_window:
            self.audio_window.show()
            self.audio_window.raise_()
            self.audio_window.activateWindow()
            self.status_widget.show_message("Audio window opened", 2)
            
    def organize_windows(self):
        """Ð£Ð¿Ð¾Ñ€ÑÐ´Ð¾Ñ‡Ð¸Ñ‚ÑŒ Ð¾ÐºÐ½Ð°"""
        desktop = QDesktopWidget()
        screen_rect = desktop.screenGeometry()
        
        # Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¾ÐºÐ½Ð¾ ÑÐ»ÐµÐ²Ð°
        self.setGeometry(50, 50, 1000, 700)
        
        # ÐžÐºÐ½Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² ÑÐ¿Ñ€Ð°Ð²Ð° ÑÐ²ÐµÑ€Ñ…Ñƒ
        if self.response_window:
            self.response_window.setGeometry(screen_rect.width() - 500, 50, 450, 400)
            self.response_window.show()
            
        # ÐžÐºÐ½Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ ÑÐ¿Ñ€Ð°Ð²Ð° ÑÐ½Ð¸Ð·Ñƒ
        if self.audio_window:
            self.audio_window.setGeometry(screen_rect.width() - 500, 470, 450, 400)
            self.audio_window.show()
            
        self.status_widget.show_message("Windows organized", 2)
        
    def setup_video_capture(self):
        for i in range(10):
            cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
            if cap.isOpened():
                ret, frame = cap.read()
                if ret:
                    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
                    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)
                    cap.set(cv2.CAP_PROP_FPS, 30)
                    
                    backend = cap.getBackendName()
                    if "DSHOW" in backend or "DirectShow" in backend:
                        self.cap = cap
                        self.status_widget.show_message(f"Connected to camera {i}", 3)
                        self.logger.info(f"Connected to camera {i}")
                        break
                cap.release()
                
        if not self.cap:
            self.status_widget.show_message("No DirectShow camera found - Audio recording available", 5)
            self.logger.warning("No DirectShow camera found")
            
    def optimize_performance(self):
        """Ð”Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"""
        # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ñ… Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹, ÑÐ½Ð¸Ð¶Ð°ÐµÐ¼ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñƒ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð²Ð¸Ð´ÐµÐ¾
        active_operations = any([
            self.ocr_worker and self.ocr_worker.isRunning(),
            self.transcription_worker and self.transcription_worker.isRunning(),
            self.response_worker and self.response_worker.isRunning(),
            self.video_widget.is_selecting,
            self.video_widget.is_panning
        ])
        
        if not active_operations and not self.performance_mode:
            self.video_timer.setInterval(100)  # 10 FPS
            self.performance_mode = True
            self.logger.debug("Switched to performance mode (10 FPS)")
        elif active_operations and self.performance_mode:
            self.video_timer.setInterval(33)   # 30 FPS
            self.performance_mode = False
            self.logger.debug("Switched to normal mode (30 FPS)")
            
    def update_frame(self):
        if self.cap and self.cap.isOpened():
            ret, frame = self.cap.read()
            if ret:
                self.current_frame = frame
                self.video_widget.set_frame(frame)
                
    def handle_selection(self, rect):
        self.selected_rect = rect
        self.copy_button.setEnabled(True)
        self.cancel_button.setEnabled(True)
        self.status_widget.show_progress("Processing OCR with GPT-4o...", 0)
        self.process_ocr()
        
    def preprocess_image(self, image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        denoised = cv2.fastNlMeansDenoising(gray)
        
        _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        kernel = np.ones((1, 1), np.uint8)
        processed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        return processed
        
    def process_ocr(self):
        if self.current_frame is None or not hasattr(self, 'selected_rect'):
            return
            
        top_left = self.video_widget.get_video_coords_from_widget(self.selected_rect.topLeft())
        bottom_right = self.video_widget.get_video_coords_from_widget(self.selected_rect.bottomRight())
        
        if not top_left or not bottom_right:
            return
            
        x1 = max(0, int(top_left.x()))
        y1 = max(0, int(top_left.y()))
        x2 = min(self.current_frame.shape[1], int(bottom_right.x()))
        y2 = min(self.current_frame.shape[0], int(bottom_right.y()))
        
        if x2 <= x1 or y2 <= y1:
            self.status_widget.show_message("Invalid selection", 3)
            return
            
        roi = self.current_frame[y1:y2, x1:x2]
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐµÑˆÐ° Ð´Ð»Ñ Ð¸Ð·Ð±ÐµÐ¶Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        roi_hash = hash(roi.tobytes())
        if roi_hash == self.last_ocr_hash:
            self.status_widget.show_message("Using cached OCR result", 2)
            return
        self.last_ocr_hash = roi_hash
        
        if self.settings.get('preprocessing', True):
            processed_roi = self.preprocess_image(roi)
            pil_image = Image.fromarray(processed_roi)
        else:
            rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_roi)
            
        if self.settings.get('ocr_language', 'eng') != 'eng':
            pytesseract.pytesseract.tesseract_cmd = pytesseract.pytesseract.tesseract_cmd
            os.environ['TESSDATA_PREFIX'] = os.path.dirname(pytesseract.pytesseract.tesseract_cmd)
            
        self.ocr_worker = OCRWorker(
            pil_image, 
            self.settings.get('use_openai', False),
            self.settings.get('api_key', ''),
            self.settings.get('model', 'gpt-4o'),
            self.settings.get('interview_mode', False)
        )
        self.ocr_worker.result_ready.connect(self.handle_ocr_result)
        self.ocr_worker.error_occurred.connect(self.handle_ocr_error)
        self.ocr_worker.progress_updated.connect(self.handle_ocr_progress)
        self.ocr_worker.start()
        
        self.logger.info("Started OCR processing with GPT-4o")
        
    @pyqtSlot(int)
    def handle_ocr_progress(self, progress):
        self.status_widget.show_progress(f"Processing OCR with GPT-4o... {progress}%", progress)
        
    @pyqtSlot(str, str, str)
    def handle_ocr_result(self, raw_text, processed_text, content_type):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        if processed_text:
            # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð¸ÐµÐ¼ Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ GPT-4o Ð¾Ñ‚Ð²ÐµÑ‚
            display_text = f"ðŸ¤– GPT-4o Response [{content_type.upper()}]\n"
            display_text += "=" * 50 + "\n\n"
            
            if content_type != "text":
                display_text += f"ðŸ“ Original OCR Text:\n{raw_text}\n\n"
                display_text += "ðŸ”„ " + "=" * 45 + "\n\n"
            
            display_text += f"âœ¨ GPT-4o Analysis:\n{processed_text}"
            
            self.text_edit.setText(display_text)
            self.add_to_history(display_text, content_type)
            
            type_labels = {
                "question": "Ð’Ð¾Ð¿Ñ€Ð¾Ñ", "task": "Ð—Ð°Ð´Ð°Ñ‡Ð°", "text": "Ð¢ÐµÐºÑÑ‚",
                "algorithm": "ÐÐ»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼", "code_review": "ÐšÐ¾Ð´-Ñ€ÐµÐ²ÑŒÑŽ", 
                "logic_puzzle": "Ð›Ð¾Ð³Ð¸ÐºÐ°", "programming_task": "ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ"
            }
            self.status_widget.show_message(f"âœ… GPT-4o: {type_labels.get(content_type, 'Ð¢ÐµÐºÑÑ‚')} Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ ({len(processed_text)} ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²)", 5)
            self.logger.info(f"OCR completed with GPT-4o: {content_type}, {len(processed_text)} characters")
        else:
            self.status_widget.show_message("OCR: Ð¢ÐµÐºÑÑ‚ Ð½Ðµ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½", 3)
            self.logger.warning("OCR: No text detected")
            
    @pyqtSlot(str)
    def handle_ocr_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        self.status_widget.show_message(f"OCR Error: {error_msg}", 10)
        self.logger.error(f"OCR Error: {error_msg}")
        self.show_error_dialog("OCR Error", error_msg)
        
    def add_to_history(self, text, content_type="text"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        preview = text[:80] + "..." if len(text) > 80 else text
        type_emoji = {
            "question": "â“", "task": "ðŸ“", "text": "ðŸ“„",
            "algorithm": "âš™ï¸", "code_review": "ðŸ”", 
            "logic_puzzle": "ðŸ§©", "programming_task": "ðŸ’»"
        }
        item_text = f"[{timestamp}] {type_emoji.get(content_type, 'ðŸ“„')} {preview}"
        
        self.history.append({
            'timestamp': timestamp,
            'text': text,
            'preview': preview,
            'type': content_type
        })
        
        self.history_list.insertItem(0, item_text)
        
        if self.history_list.count() > 100:
            self.history_list.takeItem(100)
            self.history.pop()
            
    def load_history_item(self, item):
        index = self.history_list.row(item)
        if 0 <= index < len(self.history):
            self.text_edit.setText(self.history[index]['text'])
            
    def clear_history(self):
        reply = QMessageBox.question(self, 'ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ', 
                                   'Ð’Ñ‹ ÑƒÐ²ÐµÑ€ÐµÐ½Ñ‹, Ñ‡Ñ‚Ð¾ Ñ…Ð¾Ñ‚Ð¸Ñ‚Ðµ Ð¾Ñ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð²ÑÑŽ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ?',
                                   QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.history.clear()
            self.history_list.clear()
            self.audio_history.clear()
            self.status_widget.show_message("Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°", 3)
            self.logger.info("History cleared")
            
    def copy_ocr_text(self):
        text = self.text_edit.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_widget.show_message("GPT-4o OCR result copied to clipboard", 2)
            self.logger.info("OCR text copied to clipboard")
            
    def copy_text_from_editor(self):
        text = self.text_edit.toPlainText()
        if text:
            pyperclip.copy(text)
            self.status_widget.show_message("Text copied to clipboard", 2)
            self.logger.info("Text copied to clipboard")
            
    def reset_view(self):
        self.video_widget.zoom_factor = 1.0
        self.video_widget.pan_offset = QPointF(0, 0)
        self.video_widget.selection_rect = QRectF()
        self.copy_button.setEnabled(False)
        self.status_widget.show_message("View reset", 2)
        self.logger.info("View reset")
        
    # ÐÑƒÐ´Ð¸Ð¾ Ð¼ÐµÑ‚Ð¾Ð´Ñ‹
    def toggle_recording(self):
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()
            
    def start_recording(self):
        if not self.settings.get('api_key'):
            self.show_error_dialog("Configuration Error", "Please configure OpenAI API key in Settings")
            return
            
        try:
            self.audio_worker = AudioCaptureWorker()
            self.audio_worker.audio_captured.connect(self.handle_audio_data)
            self.audio_worker.error_occurred.connect(self.handle_audio_error)
            
            self.audio_worker.start_recording()
            self.is_recording = True
            
            self.record_button.setText("â¹ï¸ Stop Recording (Ctrl+R)")
            self.record_button.setStyleSheet("QPushButton { background-color: #e74c3c; color: white; font-size: 14px; padding: 10px; }")
            self.status_widget.show_message("ðŸ”´ Recording audio...")
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¾ÐºÐ½Ðµ
            if self.audio_window:
                self.audio_window.set_recording_state(True)
                
            self.logger.info("Audio recording started")
            
        except Exception as e:
            self.status_widget.show_message(f"Audio Error: {str(e)}", 10)
            self.logger.error(f"Audio recording error: {e}")
            self.show_error_dialog("Audio Error", str(e))
            
    def stop_recording(self):
        if self.audio_worker:
            self.audio_worker.stop_recording()
            self.audio_worker.wait(5000)  # Ð–Ð´ÐµÐ¼ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 5 ÑÐµÐºÑƒÐ½Ð´
            if self.audio_worker.isRunning():
                self.audio_worker.terminate()
            self.audio_worker = None
            
        self.is_recording = False
        self.record_button.setText("ðŸŽ¤ Start Recording (Ctrl+R)")
        self.record_button.setStyleSheet("QPushButton { font-size: 14px; padding: 10px; background-color: #27ae60; color: white; }")
        self.status_widget.show_message("Ready", 2)
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¾ÐºÐ½Ðµ
        if self.audio_window:
            self.audio_window.set_recording_state(False)
            
        self.logger.info("Audio recording stopped")
        
    @pyqtSlot(bytes)
    def handle_audio_data(self, audio_data):
        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸ÑŽ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
        self.transcription_worker = TranscriptionWorker(
            audio_data, 
            self.settings, 
            self.settings.get('user_name', '')
        )
        self.transcription_worker.transcription_ready.connect(self.handle_transcription)
        self.transcription_worker.error_occurred.connect(self.handle_transcription_error)
        self.transcription_worker.progress_updated.connect(self.handle_transcription_progress)
        self.transcription_worker.start()
        
        self.status_widget.show_progress("Processing audio...", 0)
        self.cancel_button.setEnabled(True)
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¾ÐºÐ½Ðµ
        if self.audio_window:
            self.audio_window.set_status("ðŸ”„ Processing audio...")
        
    @pyqtSlot(int)
    def handle_transcription_progress(self, progress):
        self.status_widget.show_progress(f"Processing audio... {progress}%", progress)
        
    @pyqtSlot(str, str)
    def handle_transcription(self, original_text, processed_text):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¾ÐºÐ½Ð¾
        if self.audio_window:
            self.audio_window.add_transcription(f"[{timestamp}] {original_text}")
            self.audio_window.add_processed_text(f"[{timestamp}] {processed_text}")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
        self.audio_history.append({
            'timestamp': timestamp,
            'original': original_text,
            'processed': processed_text
        })
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ð»Ð¸ Ð¸Ð¼Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
        user_name = self.settings.get('user_name', '')
        if user_name and user_name.lower() in original_text.lower():
            self.status_widget.show_message(f"ðŸ‘¤ Your name mentioned! Check Quick Responses", 5)
            
            # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð¾ÐºÐ½Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¸ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹
            if self.response_window:
                self.response_window.set_question(original_text)
                self.response_window.show()
                self.response_window.raise_()
                self.generate_quick_responses_from_window(original_text)
        else:
            self.status_widget.show_message("ðŸ”´ Recording audio...")
            
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð² Ð°ÑƒÐ´Ð¸Ð¾ Ð¾ÐºÐ½Ðµ
        if self.audio_window:
            if user_name and user_name.lower() in original_text.lower():
                self.audio_window.set_status(f"ðŸ‘¤ Your name mentioned!")
            else:
                self.audio_window.set_status("ðŸ”´ Recording...")
            
        self.logger.info(f"Audio transcribed: {len(original_text)} characters")
            
    @pyqtSlot(str)
    def handle_transcription_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        self.status_widget.show_message(f"Transcription Error: {error_msg}", 10)
        
        if self.audio_window:
            self.audio_window.set_status(f"âŒ Error: {error_msg}")
            
        self.logger.error(f"Transcription Error: {error_msg}")
        self.show_error_dialog("Transcription Error", error_msg)
        
    @pyqtSlot(str)
    def handle_audio_error(self, error_msg):
        self.status_widget.show_message(f"Audio Error: {error_msg}", 10)
        
        if self.audio_window:
            self.audio_window.set_status(f"âŒ Audio Error: {error_msg}")
            
        self.logger.error(f"Audio Error: {error_msg}")
        self.show_error_dialog("Audio Error", error_msg)
        self.stop_recording()
        
    def generate_quick_responses_from_window(self, question):
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð¸Ð· Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰ÐµÐ³Ð¾ Ð¾ÐºÐ½Ð°"""
        self.generate_quick_responses(question)
        
    def generate_quick_responses(self, question=None):
        if question is None:
            question = self.response_window.question_input.text().strip() if self.response_window else ""
            
        if not question:
            return
            
        if not self.settings.get('api_key'):
            if self.response_window:
                self.response_window.set_responses("âŒ OpenAI API key not configured", "âŒ OpenAI API key not configured")
            return
            
        self.response_worker = QuickResponseWorker(
            question, 
            self.settings, 
            self.settings.get('user_name', '')
        )
        self.response_worker.response_ready.connect(self.handle_responses)
        self.response_worker.error_occurred.connect(self.handle_response_error)
        self.response_worker.progress_updated.connect(self.handle_response_progress)
        self.response_worker.start()
        
        if self.response_window:
            self.response_window.set_status("ðŸ”„ Generating GPT-4o responses...")
            
        self.status_widget.show_progress("Generating responses...", 0)
        self.cancel_button.setEnabled(True)
        
        self.logger.info("Started generating quick responses with GPT-4o")
        
    @pyqtSlot(int)
    def handle_response_progress(self, progress):
        self.status_widget.show_progress(f"Generating GPT-4o responses... {progress}%", progress)
        
    @pyqtSlot(str, str)
    def handle_responses(self, ru_response, en_response):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð¾ÐºÐ½Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²
        if self.response_window:
            if self.settings.get('enable_ru_responses', True):
                final_ru = ru_response
            else:
                final_ru = "Russian responses disabled in settings"
                
            if self.settings.get('enable_en_responses', True):
                final_en = en_response
            else:
                final_en = "English responses disabled in settings"
                
            self.response_window.set_responses(final_ru, final_en)
            
        self.status_widget.show_message("âœ… GPT-4o responses generated", 3)
        self.logger.info("Quick responses generated successfully with GPT-4o")
            
    @pyqtSlot(str)
    def handle_response_error(self, error_msg):
        self.cancel_button.setEnabled(False)
        self.status_widget.hide_progress()
        
        if self.response_window:
            self.response_window.set_responses(f"âŒ Error: {error_msg}", f"âŒ Error: {error_msg}")
            
        self.logger.error(f"Response generation error: {error_msg}")
        self.show_error_dialog("Response Generation Error", error_msg)
        
    def cancel_current_operation(self):
        """ÐžÑ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑŽ"""
        cancelled_something = False
        
        if self.ocr_worker and self.ocr_worker.isRunning():
            self.ocr_worker.cancel()
            self.ocr_worker.quit()
            self.ocr_worker.wait(3000)
            cancelled_something = True
            self.logger.info("OCR operation cancelled")
            
        if self.transcription_worker and self.transcription_worker.isRunning():
            self.transcription_worker.cancel()
            self.transcription_worker.quit()
            self.transcription_worker.wait(3000)
            cancelled_something = True
            self.logger.info("Transcription operation cancelled")
            
        if self.response_worker and self.response_worker.isRunning():
            self.response_worker.cancel()
            self.response_worker.quit()
            self.response_worker.wait(3000)
            cancelled_something = True
            self.logger.info("Response generation cancelled")
            
        if cancelled_something:
            self.cancel_button.setEnabled(False)
            self.status_widget.hide_progress()
            self.status_widget.show_message("Operation cancelled", 3)
        else:
            self.status_widget.show_message("No operations to cancel", 2)
            
    def cleanup_workers(self):
        """ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ð²ÑÐµÑ… worker'Ð¾Ð²"""
        workers = [self.ocr_worker, self.audio_worker, self.transcription_worker, self.response_worker]
        for worker in workers:
            if worker and worker.isRunning():
                worker.quit()
                worker.wait(5000)  # Ð–Ð´Ð°Ñ‚ÑŒ Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 5 ÑÐµÐºÑƒÐ½Ð´
                if worker.isRunning():
                    worker.terminate()
                    
    def autosave_data(self):
        """ÐÐ²Ñ‚Ð¾ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ…"""
        if not self.settings.get('autosave_enabled', True):
            return
            
        try:
            self.save_history_to_file()
            self.save_settings()
            self.last_autosave = datetime.now()
            self.logger.debug("Autosave completed")
        except Exception as e:
            self.logger.error(f"Autosave failed: {e}")
            
    def save_all_data(self):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð²Ñ€ÑƒÑ‡Ð½ÑƒÑŽ"""
        try:
            self.save_history_to_file()
            self.save_settings()
            self.status_widget.show_message("All data saved successfully", 3)
            self.logger.info("Manual save completed")
        except Exception as e:
            self.status_widget.show_message(f"Save failed: {str(e)}", 5)
            self.logger.error(f"Manual save failed: {e}")
            self.show_error_dialog("Save Error", str(e))
            
    def save_history_to_file(self):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² Ñ„Ð°Ð¹Ð»"""
        history_dir = Path("history")
        history_dir.mkdir(exist_ok=True)
        
        history_file = history_dir / f'history_{datetime.now().strftime("%Y%m%d")}.json'
        
        data = {
            'session_start': self.session_start_time.isoformat(),
            'last_save': datetime.now().isoformat(),
            'ocr_history': self.history,
            'audio_history': self.audio_history
        }
        
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
            
    def load_history_from_file(self):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°"""
        history_dir = Path("history")
        if not history_dir.exists():
            return
            
        history_file = history_dir / f'history_{datetime.now().strftime("%Y%m%d")}.json'
        
        if history_file.exists():
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                self.history = data.get('ocr_history', [])
                self.audio_history = data.get('audio_history', [])
                
                # Ð’Ð¾ÑÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐºÐ¸ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸
                for item in self.history:
                    timestamp = item.get('timestamp', '')
                    type_emoji = {
                        "question": "â“", "task": "ðŸ“", "text": "ðŸ“„",
                        "algorithm": "âš™ï¸", "code_review": "ðŸ”", 
                        "logic_puzzle": "ðŸ§©", "programming_task": "ðŸ’»"
                    }
                    preview = item.get('preview', '')
                    content_type = item.get('type', 'text')
                    item_text = f"[{timestamp}] {type_emoji.get(content_type, 'ðŸ“„')} {preview}"
                    self.history_list.addItem(item_text)
                    
                self.logger.info(f"Loaded history: {len(self.history)} OCR items, {len(self.audio_history)} audio items")
                
            except Exception as e:
                self.logger.error(f"Failed to load history: {e}")
                
    def export_session_data(self):
        """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÑÐµÑÑÐ¸Ð¸"""
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Export Session Data", 
                f"obs_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "JSON files (*.json)"
            )
            
            if filename:
                data = {
                    'session_start': self.session_start_time.isoformat(),
                    'export_time': datetime.now().isoformat(),
                    'settings': self.settings,
                    'ocr_history': self.history,
                    'audio_history': self.audio_history,
                    'current_ocr_text': self.text_edit.toPlainText()
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                    
                self.status_widget.show_message(f"Session data exported to {filename}", 5)
                self.logger.info(f"Session data exported to {filename}")
                
        except Exception as e:
            self.status_widget.show_message(f"Export failed: {str(e)}", 5)
            self.logger.error(f"Export failed: {e}")
            self.show_error_dialog("Export Error", str(e))
            
    def export_history(self):
        """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸"""
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Export History", 
                f"obs_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                "JSON files (*.json)"
            )
            
            if filename:
                data = {
                    'export_time': datetime.now().isoformat(),
                    'ocr_history': self.history,
                    'audio_history': self.audio_history
                }
                
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
                    
                self.status_widget.show_message(f"History exported to {filename}", 5)
                self.logger.info(f"History exported to {filename}")
                
        except Exception as e:
            self.show_error_dialog("Export Error", str(e))
            
    def save_ocr_text(self):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ OCR Ð² Ñ„Ð°Ð¹Ð»"""
        text = self.text_edit.toPlainText()
        if not text:
            self.status_widget.show_message("No OCR text to save", 3)
            return
            
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save OCR Text", 
                f"gpt4o_ocr_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "Text files (*.txt)"
            )
            
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.status_widget.show_message(f"GPT-4o OCR text saved to {filename}", 3)
                
        except Exception as e:
            self.show_error_dialog("Save Error", str(e))
            
    def save_audio_text(self):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚ÐµÐºÑÑ‚ Ð² Ñ„Ð°Ð¹Ð»"""
        if not self.audio_window:
            return
            
        text = self.audio_window.processed_area.toPlainText()
        if not text:
            self.status_widget.show_message("No audio text to save", 3)
            return
            
        try:
            filename, _ = QFileDialog.getSaveFileName(
                self, 
                "Save Audio Text", 
                f"audio_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                "Text files (*.txt)"
            )
            
            if filename:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.status_widget.show_message(f"Audio text saved to {filename}", 3)
                
        except Exception as e:
            self.show_error_dialog("Save Error", str(e))
            
    def show_error_dialog(self, title, message):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð¾ÑˆÐ¸Ð±ÐºÐ¸"""
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Critical)
        msg.setWindowTitle(title)
        msg.setText(message)
        msg.exec_()
        
    def show_help(self):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ"""
        help_text = """
        <h2>OBS Complete Assistant - Optimized Version</h2>
        
        <h3>ðŸŽ® Ð“Ð¾Ñ€ÑÑ‡Ð¸Ðµ ÐºÐ»Ð°Ð²Ð¸ÑˆÐ¸:</h3>
        <ul>
        <li><b>Ctrl+C</b> - ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ OCR Ñ‚ÐµÐºÑÑ‚</li>
        <li><b>Ctrl+R</b> - ÐÐ°Ñ‡Ð°Ñ‚ÑŒ/Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð°ÑƒÐ´Ð¸Ð¾</li>
        <li><b>Ctrl+S</b> - Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ</li>
        <li><b>Ctrl+E</b> - Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ ÑÐµÑÑÐ¸Ð¸</li>
        <li><b>Ctrl+1</b> - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²</li>
        <li><b>Ctrl+2</b> - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¾ÐºÐ½Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ð¸</li>
        <li><b>Esc</b> - ÐžÑ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸ÑŽ</li>
        <li><b>F1</b> - ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ ÑÑ‚Ñƒ ÑÐ¿Ñ€Ð°Ð²ÐºÑƒ</li>
        </ul>
        
        <h3>ðŸªŸ ÐŸÐ»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°:</h3>
        <ul>
        <li><b>Response Window</b> - Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ñ GPT-4o Ð½Ð° Ð´Ð²ÑƒÑ… ÑÐ·Ñ‹ÐºÐ°Ñ…</li>
        <li><b>Audio Window</b> - Ð¢Ñ€Ð°Ð½ÑÐºÑ€Ð¸Ð¿Ñ†Ð¸Ñ Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾ Ð² Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸</li>
        <li>ÐžÐºÐ½Ð° Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°ÐºÑ€ÐµÐ¿Ð¸Ñ‚ÑŒ Ð¿Ð¾Ð²ÐµÑ€Ñ… Ð²ÑÐµÑ… Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ñ…</li>
        <li>ÐžÐºÐ½Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑƒÐ¿Ð¾Ñ€ÑÐ´Ð¾Ñ‡Ð¸Ð²Ð°ÑŽÑ‚ÑÑ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ</li>
        </ul>
        
        <h3>ðŸ¤– GPT-4o Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ:</h3>
        <ul>
        <li>Ð’ÑÐµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽÑ‚ÑÑ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ GPT-4o</li>
        <li>Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ñ‹ Ð´Ð»Ñ ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸Ð¹</li>
        <li>ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°</li>
        <li>Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²</li>
        </ul>
        
        <h3>ðŸ“¹ Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾:</h3>
        <ul>
        <li><b>Ð›ÐµÐ²Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ° Ð¼Ñ‹ÑˆÐ¸</b> - Ð’Ñ‹Ð´ÐµÐ»Ð¸Ñ‚ÑŒ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ð´Ð»Ñ OCR</li>
        <li><b>ÐŸÑ€Ð°Ð²Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ° Ð¼Ñ‹ÑˆÐ¸ + Ð¿ÐµÑ€ÐµÑ‚Ð°ÑÐºÐ¸Ð²Ð°Ð½Ð¸Ðµ</b> - ÐŸÐ°Ð½Ð¾Ñ€Ð°Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ</li>
        <li><b>ÐšÐ¾Ð»ÐµÑÐ¸ÐºÐ¾ Ð¼Ñ‹ÑˆÐ¸</b> - Ð—ÑƒÐ¼</li>
        </ul>
        """
        
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setWindowTitle("Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ°")
        msg.setText(help_text)
        msg.setTextFormat(Qt.RichText)
        msg.exec_()
        
    def show_about(self):
        """ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ðµ"""
        about_text = f"""
        <h2>OBS Complete Assistant</h2>
        <p><b>Optimized Version with Floating Windows</b></p>
        <p>Ð’ÐµÑ€ÑÐ¸Ñ: 3.0</p>
        <p>Ð”Ð°Ñ‚Ð°: {datetime.now().strftime('%Y-%m-%d')}</p>
        
        <p>ÐŸÐ¾Ð»Ð½Ð¾Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº Ñ:</p>
        <ul>
        <li>ðŸ“¹ Ð—Ð°Ñ…Ð²Ð°Ñ‚ Ð²Ð¸Ð´ÐµÐ¾ Ð¸Ð· OBS Virtual Camera</li>
        <li>ðŸ“ OCR Ñ GPT-4o Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¾Ð¹</li>
        <li>ðŸŽ¤ Ð—Ð°Ñ…Ð²Ð°Ñ‚ Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾</li>
        <li>ðŸ’¬ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð½Ð° ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸ÑÑ…</li>
        <li>ðŸªŸ ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°</li>
        <li>ðŸŽ¯ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ Ð½Ð° ÑÐ¾Ð±ÐµÑÐµÐ´Ð¾Ð²Ð°Ð½Ð¸ÑÑ…</li>
        </ul>
        
        <p><b>ÐÐ¾Ð²Ð¾Ðµ Ð² ÑÑ‚Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸:</b></p>
        <ul>
        <li>ðŸªŸ ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾ÐºÐ½Ð° Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹</li>
        <li>ðŸ¤– Ð§ÐµÑ‚ÐºÐ¾Ðµ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ GPT-4o Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²</li>
        <li>âš¡ ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ</li>
        <li>ðŸ“Œ Ð—Ð°ÐºÑ€ÐµÐ¿Ð»ÐµÐ½Ð¸Ðµ Ð¾ÐºÐ¾Ð½ Ð¿Ð¾Ð²ÐµÑ€Ñ… Ð²ÑÐµÑ…</li>
        </ul>
        
        <p>Ð¢ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸: PyQt5, OpenCV, Tesseract, OpenAI GPT-4o API</p>
        """
        
        msg = QMessageBox()
        msg.setIcon(QMessageBox.Information)
        msg.setWindowTitle("Ðž Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ðµ")
        msg.setText(about_text)
        msg.setTextFormat(Qt.RichText)
        msg.exec_()
        
    def open_settings(self):
        dialog = SettingsDialog(self, self.settings)
        if dialog.exec_():
            old_floating = self.settings.get('floating_windows', True)
            self.settings = dialog.get_settings()
            self.save_settings()
            self.status_widget.show_message("Settings updated", 3)
            self.logger.info("Settings updated")
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
            log_level = getattr(logging, self.settings.get('log_level', 'INFO'))
            logging.getLogger().setLevel(log_level)
            
            # Ð•ÑÐ»Ð¸ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð°ÑÑŒ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ñ… Ð¾ÐºÐ¾Ð½
            new_floating = self.settings.get('floating_windows', True)
            if old_floating != new_floating:
                if new_floating and not self.response_window:
                    self.setup_floating_windows()
                elif not new_floating and self.response_window:
                    self.response_window.hide()
                    self.audio_window.hide()
            
    def clear_all_text(self):
        reply = QMessageBox.question(self, 'ÐŸÐ¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ', 
                                   'ÐžÑ‡Ð¸ÑÑ‚Ð¸Ñ‚ÑŒ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚? Ð­Ñ‚Ð¾ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ Ð½ÐµÐ»ÑŒÐ·Ñ Ð¾Ñ‚Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ.',
                                   QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.text_edit.clear()
            
            if self.response_window:
                self.response_window.ru_response_area.clear()
                self.response_window.en_response_area.clear()
                self.response_window.question_input.clear()
                
            if self.audio_window:
                self.audio_window.clear_all_text()
                
            self.status_widget.show_message("All text cleared", 3)
            self.logger.info("All text cleared")
        
    def keyPressEvent(self, event):
        if event.key() == Qt.Key_C and event.modifiers() == Qt.ControlModifier:
            self.copy_ocr_text()
            
    def closeEvent(self, event):
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿ÐµÑ€ÐµÐ´ Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸ÐµÐ¼
        self.save_all_data()
        
        # Ð¡ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð¿Ð»Ð°Ð²Ð°ÑŽÑ‰Ð¸Ðµ Ð¾ÐºÐ½Ð°
        if self.response_window:
            self.response_window.hide()
        if self.audio_window:
            self.audio_window.hide()
        
        # ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° Ñ€ÐµÑÑƒÑ€ÑÐ¾Ð²
        if self.cap:
            self.cap.release()
        self.stop_recording()
        self.cleanup_workers()
        
        self.logger.info("Application closed")
        event.accept()


def main():
    app = QApplication(sys.argv)
    app.setApplicationName("OBS Complete Assistant Optimized")
    app.setApplicationVersion("3.0")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ sounddevice
    try:
        import sounddevice as sd
        print("âœ… sounddevice loaded successfully")
    except ImportError:
        print("âš ï¸ sounddevice not installed. Audio features will be limited.")
        print("Run: pip install sounddevice")
    
    window = OBSCompleteAssistantOptimized()
    window.show()
    
    # ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑƒÐ¿Ð¾Ñ€ÑÐ´Ð¾Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð¾ÐºÐ½Ð° Ð¿Ñ€Ð¸ Ð·Ð°Ð¿ÑƒÑÐºÐµ
    QTimer.singleShot(1000, window.organize_windows)
    
    try:
        sys.exit(app.exec_())
    except Exception as e:
        print(f"Application error: {e}")
        window.logger.error(f"Application error: {e}")


if __name__ == "__main__":
    main()